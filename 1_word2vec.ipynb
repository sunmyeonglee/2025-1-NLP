{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunmyeonglee/2025-1-NLP/blob/main/1_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXQsDEWukzqU"
      },
      "source": [
        "# Word2Vec Implementation from Scratch\n",
        "\n",
        "This notebook demonstrates how to implement the Word2Vec algorithm from scratch using PyTorch. We'll use the first Harry Potter book as our corpus to train word embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnl2eGwPkzqW"
      },
      "source": [
        "## 1. Setting Up the Environment\n",
        "\n",
        "First, we need to import the necessary libraries:\n",
        "- `torch` and `torch.nn` for tensor operations and neural network functionality\n",
        "- `string` for string manipulations (removing punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L9BA5Lg2QRMr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lUq3GHEkzqX"
      },
      "source": [
        "## 2. Getting the Text Data\n",
        "\n",
        "We'll download the first Harry Potter book to use as our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tEaaz_s0QRMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9392dfab-5f78-4ecb-c468-b9c36ea7595a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-27 04:26:29--  https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439742 (429K) [text/plain]\n",
            "Saving to: ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt’\n",
            "\n",
            "J. K. Rowling - Har 100%[===================>] 429.44K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-27 04:26:29 (6.60 MB/s) - ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt’ saved [439742/439742]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZzrT5mfkzqX"
      },
      "source": [
        "## 3. Text Preprocessing\n",
        "\n",
        "Before we can use the text data, we need to preprocess it:\n",
        "- Remove punctuation\n",
        "- Convert text to lowercase\n",
        "- Split text into tokens (words)\n",
        "\n",
        "This function will help us clean and tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CUsXJYlIQRMs"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(x):\n",
        "  return x.translate(''.maketrans('', '', string.punctuation))\n",
        "\n",
        "def make_tokenized_corpus(corpus):\n",
        "  out= [ [y.lower() for y in remove_punctuation(sentence).split(' ') if y] for sentence in corpus]\n",
        "  return [x for x in out if x!=[]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw404pzckzqY"
      },
      "source": [
        "## 4. Loading and Formatting the Text\n",
        "\n",
        "Now we'll load the text file, replace some special characters, and split the text into sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ry1o-F-bQRMs"
      },
      "outputs": [],
      "source": [
        "with open(\"J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\", 'r') as f:\n",
        "  strings = f.readlines()\n",
        "list_of_sentences = \"\".join(strings).replace('\\n', ' ').replace('Mr.', 'mr').replace('Mrs.', 'mrs').split('. ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORi6DgWjkzqY"
      },
      "source": [
        "Let's tokenize the text using our preprocessing function `make_tokenized_corpus`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ne-pUaxSQRMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdeeb8f-3cd6-4b9a-9208-b0a140ed2961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry Potter and the Sorcerer's Stone   CHAPTER ONE  THE BOY WHO LIVED  mr and mrs Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much\n",
            "They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense\n",
            " mr Dursley was the director of a firm called Grunnings, which made drills\n",
            "He was a big, beefy man with hardly any neck, although he did have a very large mustache\n",
            "mrs Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors\n",
            "The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere\n",
            " The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it\n",
            "They didn't think they could bear it if anyone found out about the Potters\n",
            "mrs Potter was mrs Dursley's sister, but they hadn't met for several years; in fact, mrs Dursley pretended she didn't have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be\n",
            "The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street\n"
          ]
        }
      ],
      "source": [
        "# Corpus is a list of list of strings (words)\n",
        "\n",
        "for sentence in list_of_sentences[:10]:\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = make_tokenized_corpus(list_of_sentences)\n",
        "\n",
        "type(corpus), type(corpus[0]), type(corpus[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpiLxjWqn-wG",
        "outputId": "fdc0bfd8-9a06-45b0-8592-ef66a7bbffe9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list, str)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUqwddUAkzqY"
      },
      "source": [
        "## 5. Creating Context Word Pairs\n",
        "\n",
        "A key concept in Word2Vec is learning from context. We need to create pairs of words that appear near each other in the text. We'll use a sliding window approach to create these pairs.\n",
        "\n",
        "For example, with the window size of 2, for the word \"to\" in the sentence \"they were the last people youd expect to be involved...\", we would create pairs with:\n",
        "- (\"to\", \"expect\")\n",
        "- (\"to\", \"be\")\n",
        "- (\"to\", \"involved\")\n",
        "- (\"to\", \"in\")\n",
        "\n",
        "These pairs will be our training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-UxJwTAacWfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43eed45-8345-4b49-9e6b-6967018bc248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4682/4682 [00:00<00:00, 8800.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Length of word_pairs is 282372\n",
            "First 5 example of word_pairs is [('harry', 'potter'), ('harry', 'and'), ('potter', 'harry'), ('potter', 'and'), ('potter', 'the')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "sample_sentence = ['they', 'were', 'the', 'last', 'people', 'youd', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'nonsense']\n",
        "\n",
        "word_pairs = []\n",
        "window_size = 2\n",
        "\n",
        "for sample_sentence in tqdm(corpus):\n",
        "  for cur_idx, center_word in enumerate(sample_sentence):\n",
        "    window_begin = max(cur_idx - window_size, 0)\n",
        "    window_end = min(cur_idx + window_size + 1, len(sample_sentence))\n",
        "    # for context_word in sample_sentence[window_begin:window_end]:\n",
        "    #   # if center_word == context_word: continue\n",
        "    #   word_pairs.append( (center_word, context_word))\n",
        "    for j in range(window_begin, window_end):\n",
        "      if cur_idx == j: continue\n",
        "      word_pairs.append( (center_word, sample_sentence[j]))\n",
        "\n",
        "print(f\"\\nLength of word_pairs is {len(word_pairs)}\")\n",
        "print(f\"First 5 example of word_pairs is {word_pairs[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aELIKMG2kzqZ"
      },
      "source": [
        "## 6. Building the Vocabulary\n",
        "\n",
        "To work with word vectors, we need to create a vocabulary that maps each unique word to an index. We'll also filter out rare words that appear less than a certain number of times in the corpus.\n",
        "\n",
        "### 6.1 Collecting All Words\n",
        "\n",
        "First, let's collect all words in our corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "htinJiMPkkRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a60b8cc-7877-4301-d3c9-84d271cc2ab0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77597"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# we have to make vocabulary\n",
        "sentence = corpus[0]\n",
        "entire_words = []\n",
        "\n",
        "for sentence in corpus:\n",
        "  for word in sentence:\n",
        "    entire_words.append(word)\n",
        "\n",
        "len(entire_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACx84hwWkzqZ"
      },
      "source": [
        "\n",
        "### 6.2 Finding Unique Words\n",
        "\n",
        "Now, let's find the unique words in our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERBFCjeslgDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d50b93-c6bf-4c04-b4e6-ece98a8af977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6038"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# we have to get the \"unique\" item among total words\n",
        "\n",
        "vocab_set = set(entire_words)\n",
        "len(vocab_set)\n",
        "\n",
        "unique_words = list(vocab_set)\n",
        "len(unique_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2gGyVUqkzqZ"
      },
      "source": [
        "### 6.3 Converting to a List and Sorting\n",
        "\n",
        "We'll convert the set of unique words to a sorted list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fDJNrHdhl_dk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99a4fbf6-ea45-49eb-ecf3-6355fa8d0e4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# vocab_set[0] # set is not subscriptable because it has no order\n",
        "\n",
        "unique_words = sorted(list(unique_words))\n",
        "unique_words[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coTM3X2ikzqZ"
      },
      "source": [
        "### 6.4 Filtering by Frequency\n",
        "\n",
        "Now, let's filter out rare words that occur less than a specified number of times:\n",
        "- We can use the `Counter` class from the `collections` module to count the frequency of each word in the corpus.\n",
        "- Caution on `alist.sort()` will return `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wOkBSjrkmNE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c597fd-c7dd-43a2-dd0f-1d2c2d50125f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'able',\n",
              " 'abou',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'added',\n",
              " 'afford',\n",
              " 'afraid',\n",
              " 'after']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# how can we filter the vocab by its frequency?\n",
        "filtered_vocab = None\n",
        "# you can use word counter as dictionary\n",
        "# In python dictionary, dict.keys() gives keys, and dict.values() give values,\n",
        "# dict.items() give (key, value)\n",
        "\n",
        "from collections import Counter\n",
        "word_counter = Counter(entire_words)\n",
        "word_counter.most_common(10)\n",
        "word_counter['harry']\n",
        "\n",
        "threshold = 5\n",
        "filtered_vocab = []\n",
        "for key, value in word_counter.items():\n",
        "  if value > threshold:\n",
        "    filtered_vocab.append(key)\n",
        "\n",
        "filtered_vocab.sort()\n",
        "filtered_vocab[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3UPyaOQkzqZ"
      },
      "source": [
        "## 7. Filtering Word Pairs\n",
        "\n",
        "Now that we have our filtered vocabulary, we need to filter our word pairs to only include words that are in our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XUS6U7y7opUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c315024f-d72b-4277-b8f9-0f839997e2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 282372/282372 [00:14<00:00, 19541.60it/s]\n"
          ]
        }
      ],
      "source": [
        "# Filter the word_pairs using the vocab\n",
        "# word_pairs, filtered_vocab\n",
        "# word_pairs is a list of [word_a, word_b]\n",
        "\n",
        "filtered_word_pairs = []\n",
        "vocab_set = set(filtered_vocab)\n",
        "\n",
        "for pair in tqdm(word_pairs):\n",
        "  a, b = pair\n",
        "  if a in filtered_vocab and b in filtered_vocab:\n",
        "    filtered_word_pairs.append(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U-o4UucOrcem"
      },
      "outputs": [],
      "source": [
        "# implement same algorithm with list comprehension\n",
        "\n",
        "filtered_word_pairs = [pair for pair in word_pairs if pair[0] in vocab_set and pair[1] in vocab_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Uz_8ch59ps_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ea6701-2e90-4013-8b9f-e059e85c2ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(226846, 282372)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(filtered_word_pairs), len(word_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdAwmBykzqZ"
      },
      "source": [
        "## 8. Converting Words to Indices\n",
        "\n",
        "For efficiency, we'll convert our words to indices according to their position in our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VFJfhOznqyi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1b865b-bded-4152-8664-3efd8965ddfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "527"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# convert word into index of vocab\n",
        "# filtered_vocab.index('happily')\n",
        "filtered_vocab.index('harry')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Iv7dxRkzqZ"
      },
      "source": [
        "This is inefficient because `list.index()` has to scan the list every time. Let's use a dictionary for faster lookups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2D8n16VitIHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224f9678-705f-43ec-81e5-8b78bd663dd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "527"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# we can make it faster\n",
        "# use dictionary to find the index of string\n",
        "word2idx = dict()\n",
        "for idx, word in enumerate(filtered_vocab):\n",
        "  word2idx[word] = idx\n",
        "\n",
        "word2idx['harry']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQr7ddPnkzqa"
      },
      "source": [
        "Now, let's convert our word pairs to index pairs more efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "utXemuOgt8-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d2c890-7541-4ace-a9f7-22e1cc4d0f68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(527, 953)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "index_pairs = [(word2idx[pair[0]], word2idx[pair[1]]) for pair in filtered_word_pairs]\n",
        "index_pairs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KgQ_oSNGuZAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9a9e62a-8194-4c67-ecc9-f9ef30b6fa32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'harry'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Why we don't need idx2tok?\n",
        "\n",
        "filtered_vocab[527]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2igwOubJkzqa"
      },
      "source": [
        "## 9. Creating Initial Word Vectors\n",
        "\n",
        "Now we'll create random vectors for each word in our vocabulary. These vectors will be adjusted during training:\n",
        "- We can use `torch.randn` to create random vectors that follow normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ygV93qzDu4Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a646435f-caa8-4157-a28a-d3cd6c7bac1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0039, -0.0132,  0.0306,  ..., -0.2251, -0.0883, -0.0780],\n",
              "        [ 0.0087, -0.0513,  0.1240,  ...,  0.0181,  0.1080, -0.0013],\n",
              "        [ 0.0428, -0.0833, -0.0558,  ...,  0.0198,  0.1067,  0.0584],\n",
              "        ...,\n",
              "        [-0.0225, -0.0932,  0.0323,  ..., -0.1122, -0.0098,  0.0578],\n",
              "        [-0.1467, -0.2946, -0.0369,  ..., -0.1944,  0.0291,  0.0371],\n",
              "        [ 0.1634, -0.0023, -0.0396,  ..., -0.0037,  0.0359,  0.0007]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# we have to make random vectors for each word in the vocab\n",
        "# we also have to decide the dimension of the vector\n",
        "\n",
        "dim = 100\n",
        "vocab_size = len(filtered_vocab)\n",
        "\n",
        "word_vectors = torch.randn(vocab_size, dim) / dim ** 0.5\n",
        "word_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vmZcT53rvwW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df99a4b3-b4f7-493f-bc5e-544738dffbfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0347,  0.0097, -0.1745, -0.1108,  0.0955, -0.0299, -0.1880, -0.0730,\n",
              "         0.0063,  0.0325,  0.1199, -0.0225, -0.0570,  0.0811, -0.1121, -0.0258,\n",
              "        -0.0211, -0.0510, -0.1001, -0.0829, -0.1335, -0.1573,  0.0228,  0.3139,\n",
              "         0.1000, -0.0136,  0.0557, -0.0939,  0.0649,  0.0431, -0.1296,  0.0283,\n",
              "        -0.0605,  0.1312,  0.1316,  0.1278, -0.1840,  0.0721, -0.2079,  0.1430,\n",
              "         0.0493, -0.0241, -0.0351, -0.0729,  0.0218,  0.0673, -0.1201,  0.0345,\n",
              "        -0.0379, -0.0365, -0.0627, -0.1535,  0.0080,  0.0159, -0.0142, -0.0642,\n",
              "        -0.0637,  0.1281, -0.0136, -0.1404,  0.2779,  0.1085, -0.1176, -0.0518,\n",
              "        -0.0418,  0.0391, -0.0661, -0.1507, -0.0971, -0.1463,  0.1127,  0.0988,\n",
              "         0.0957,  0.0760,  0.1998, -0.0615,  0.0342, -0.0384,  0.0005,  0.0451,\n",
              "         0.0550, -0.1598, -0.0536,  0.0600, -0.0609, -0.1395, -0.1332,  0.0577,\n",
              "        -0.0660,  0.0337, -0.1576,  0.0438,  0.0638, -0.0353,  0.0062, -0.0049,\n",
              "         0.0555,  0.0160,  0.0824, -0.0552])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# what is the vector for harry?\n",
        "word_vectors[word2idx['harry']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUCg10rHkzqa"
      },
      "source": [
        "## 10. Understanding Word Relationships with Dot Products\n",
        "\n",
        "The core of Word2Vec is using dot products to measure relationships between words. Let's explore this concept:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "J4bEKFvUxbVv"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(sci_mode=False) # Do this to avoid scientific notation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaCMWmD6Suhy"
      },
      "source": [
        "## Dot Product\n",
        "- Assume we have two vectors $a$ and $b$.\n",
        "  - $a = [a_1, a_2, a_3, a_4, ..., a_n]$\n",
        "  - $b = [b_1, b_2, b_3, b_4, ..., b_n]$\n",
        "- $a \\cdot b$ = $\\sum _{i=1}^n a_ib_i$  = $a_1b_1 + a_2b_2 + a_3b_3 + a_4b_4 + ... + a_nb_n$\n",
        "\n",
        "Let's calculate the dot product between \"harry\" and \"potter\":\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gsse-jUrw6c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171f2f1c-152d-4c38-cbd0-fefa9cb523ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0057)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# calculate P(potter|harry)\n",
        "harry = word_vectors[word2idx['harry']]\n",
        "potter = word_vectors[word2idx['potter']]\n",
        "dot_product_value_between_potter_harry = sum(harry * potter)\n",
        "dot_product_value_between_potter_harry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wZrLEY36yBNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77c40b1-c5d6-4b2a-de90-823a7b132590"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': tensor(-0.0915),\n",
              " 'able': tensor(-0.0140),\n",
              " 'abou': tensor(0.0766),\n",
              " 'about': tensor(0.1487),\n",
              " 'above': tensor(0.2486),\n",
              " 'across': tensor(0.0983),\n",
              " 'added': tensor(0.1583),\n",
              " 'afford': tensor(-0.0539),\n",
              " 'afraid': tensor(0.0185),\n",
              " 'after': tensor(0.0300),\n",
              " 'afternoon': tensor(0.0717),\n",
              " 'again': tensor(-0.1002),\n",
              " 'against': tensor(0.1221),\n",
              " 'ages': tensor(0.0078),\n",
              " 'ago': tensor(-0.0893),\n",
              " 'agreed': tensor(-0.0126),\n",
              " 'ah': tensor(0.1042),\n",
              " 'ahead': tensor(-0.0998),\n",
              " 'air': tensor(0.0521),\n",
              " 'albus': tensor(0.0516),\n",
              " 'alive': tensor(0.0129),\n",
              " 'all': tensor(0.0975),\n",
              " 'alley': tensor(-0.0053),\n",
              " 'allowed': tensor(0.1409),\n",
              " 'almost': tensor(0.1099),\n",
              " 'alone': tensor(0.0488),\n",
              " 'along': tensor(0.0290),\n",
              " 'already': tensor(-0.0485),\n",
              " 'also': tensor(0.0115),\n",
              " 'although': tensor(-0.0530),\n",
              " 'always': tensor(0.1434),\n",
              " 'am': tensor(-0.0566),\n",
              " 'an': tensor(0.0788),\n",
              " 'and': tensor(0.1218),\n",
              " 'angrily': tensor(0.0627),\n",
              " 'angry': tensor(0.0898),\n",
              " 'another': tensor(0.0418),\n",
              " 'answer': tensor(0.0737),\n",
              " 'any': tensor(-0.0906),\n",
              " 'anymore': tensor(-0.1087),\n",
              " 'anyone': tensor(-0.2098),\n",
              " 'anythin': tensor(-0.0271),\n",
              " 'anything': tensor(0.0256),\n",
              " 'anyway': tensor(0.0382),\n",
              " 'anywhere': tensor(-0.0515),\n",
              " 'apart': tensor(0.0441),\n",
              " 'appeared': tensor(-0.0112),\n",
              " 'are': tensor(0.0730),\n",
              " 'arent': tensor(-0.0407),\n",
              " 'arm': tensor(0.0317),\n",
              " 'armor': tensor(-0.0329),\n",
              " 'arms': tensor(0.0230),\n",
              " 'around': tensor(-0.3083),\n",
              " 'arrived': tensor(-0.0252),\n",
              " 'arts': tensor(0.0007),\n",
              " 'as': tensor(-0.1830),\n",
              " 'ask': tensor(-0.0738),\n",
              " 'asked': tensor(0.0036),\n",
              " 'asking': tensor(0.0392),\n",
              " 'asleep': tensor(0.0494),\n",
              " 'at': tensor(0.0628),\n",
              " 'attention': tensor(-0.0574),\n",
              " 'aunt': tensor(-0.0976),\n",
              " 'awake': tensor(-0.1792),\n",
              " 'away': tensor(0.0460),\n",
              " 'baby': tensor(-0.0674),\n",
              " 'back': tensor(-0.1046),\n",
              " 'backward': tensor(0.0482),\n",
              " 'bacon': tensor(0.1851),\n",
              " 'bad': tensor(-0.0313),\n",
              " 'bag': tensor(0.0471),\n",
              " 'ball': tensor(0.0107),\n",
              " 'balls': tensor(0.0877),\n",
              " 'bane': tensor(0.0106),\n",
              " 'barrier': tensor(-0.0424),\n",
              " 'be': tensor(0.0134),\n",
              " 'beans': tensor(-0.1636),\n",
              " 'beard': tensor(-0.0769),\n",
              " 'became': tensor(-0.0625),\n",
              " 'because': tensor(0.0349),\n",
              " 'become': tensor(-0.1214),\n",
              " 'bed': tensor(-0.0253),\n",
              " 'bedroom': tensor(0.0525),\n",
              " 'been': tensor(-0.0706),\n",
              " 'before': tensor(-0.0411),\n",
              " 'began': tensor(0.2343),\n",
              " 'behind': tensor(0.1051),\n",
              " 'being': tensor(0.0574),\n",
              " 'believe': tensor(-0.0492),\n",
              " 'below': tensor(-0.0651),\n",
              " 'beneath': tensor(0.0077),\n",
              " 'bent': tensor(-0.0506),\n",
              " 'best': tensor(0.0405),\n",
              " 'bet': tensor(0.2148),\n",
              " 'better': tensor(-0.0045),\n",
              " 'between': tensor(-0.0094),\n",
              " 'big': tensor(0.0076),\n",
              " 'bill': tensor(-0.0326),\n",
              " 'bin': tensor(-0.0425),\n",
              " 'binoculars': tensor(-0.1284),\n",
              " 'birthday': tensor(0.0359),\n",
              " 'bit': tensor(0.0078),\n",
              " 'black': tensor(0.0783),\n",
              " 'blankets': tensor(-0.0208),\n",
              " 'blew': tensor(0.2114),\n",
              " 'blood': tensor(-0.1103),\n",
              " 'bloody': tensor(0.0680),\n",
              " 'bludger': tensor(0.0111),\n",
              " 'bludgers': tensor(0.0923),\n",
              " 'blue': tensor(0.1048),\n",
              " 'board': tensor(0.1261),\n",
              " 'boat': tensor(0.0184),\n",
              " 'boats': tensor(-0.1099),\n",
              " 'body': tensor(-0.1384),\n",
              " 'book': tensor(0.1730),\n",
              " 'books': tensor(-0.1212),\n",
              " 'both': tensor(0.0597),\n",
              " 'bottle': tensor(0.1518),\n",
              " 'bottles': tensor(-0.1199),\n",
              " 'bottom': tensor(-0.0225),\n",
              " 'bought': tensor(-0.0729),\n",
              " 'bowed': tensor(0.1951),\n",
              " 'box': tensor(-0.0659),\n",
              " 'boy': tensor(-0.0901),\n",
              " 'boys': tensor(0.0312),\n",
              " 'branches': tensor(-0.1111),\n",
              " 'brave': tensor(0.2063),\n",
              " 'break': tensor(0.0969),\n",
              " 'breakfast': tensor(-0.0208),\n",
              " 'breaking': tensor(-0.0512),\n",
              " 'breath': tensor(0.1269),\n",
              " 'breathing': tensor(-0.0409),\n",
              " 'bright': tensor(0.1313),\n",
              " 'brilliant': tensor(-0.1103),\n",
              " 'broke': tensor(-0.0660),\n",
              " 'broken': tensor(0.0175),\n",
              " 'broom': tensor(-0.1217),\n",
              " 'brooms': tensor(0.0222),\n",
              " 'broomstick': tensor(0.1001),\n",
              " 'broomsticks': tensor(-0.1436),\n",
              " 'brother': tensor(0.0955),\n",
              " 'brothers': tensor(-0.0138),\n",
              " 'brought': tensor(0.1522),\n",
              " 'brown': tensor(-0.2877),\n",
              " 'burst': tensor(0.0803),\n",
              " 'business': tensor(0.0566),\n",
              " 'busy': tensor(-0.0403),\n",
              " 'but': tensor(-0.0228),\n",
              " 'buy': tensor(0.0472),\n",
              " 'by': tensor(-0.0958),\n",
              " 'cake': tensor(0.0151),\n",
              " 'cakes': tensor(0.1563),\n",
              " 'call': tensor(0.1335),\n",
              " 'called': tensor(-0.0884),\n",
              " 'came': tensor(-0.0462),\n",
              " 'can': tensor(-0.0640),\n",
              " 'cant': tensor(-0.0110),\n",
              " 'car': tensor(0.1844),\n",
              " 'card': tensor(-0.1040),\n",
              " 'care': tensor(-0.1432),\n",
              " 'careful': tensor(-0.1182),\n",
              " 'carefully': tensor(0.0492),\n",
              " 'carried': tensor(0.1121),\n",
              " 'carrying': tensor(0.1132),\n",
              " 'cart': tensor(0.0578),\n",
              " 'case': tensor(-0.1526),\n",
              " 'castle': tensor(0.0697),\n",
              " 'cat': tensor(0.1185),\n",
              " 'catch': tensor(-0.0559),\n",
              " 'cats': tensor(-0.0069),\n",
              " 'caught': tensor(-0.0333),\n",
              " 'cauldron': tensor(-0.0246),\n",
              " 'cause': tensor(-0.0668),\n",
              " 'ceiling': tensor(-0.0770),\n",
              " 'centaur': tensor(0.0623),\n",
              " 'certainly': tensor(0.0393),\n",
              " 'chair': tensor(0.0109),\n",
              " 'chamber': tensor(-0.1501),\n",
              " 'chance': tensor(-0.1578),\n",
              " 'change': tensor(-0.1267),\n",
              " 'changed': tensor(0.0272),\n",
              " 'chapter': tensor(0.0846),\n",
              " 'charlie': tensor(0.0181),\n",
              " 'charlies': tensor(0.0709),\n",
              " 'charms': tensor(0.1190),\n",
              " 'chasers': tensor(0.0218),\n",
              " 'cheer': tensor(-0.0118),\n",
              " 'cheering': tensor(-0.0988),\n",
              " 'cheers': tensor(0.1360),\n",
              " 'chess': tensor(0.0491),\n",
              " 'chessmen': tensor(-0.1546),\n",
              " 'chest': tensor(-0.0381),\n",
              " 'chocolate': tensor(-0.0519),\n",
              " 'christmas': tensor(-0.0087),\n",
              " 'chuckled': tensor(0.0342),\n",
              " 'clambered': tensor(-0.2018),\n",
              " 'clapped': tensor(0.1374),\n",
              " 'class': tensor(0.2041),\n",
              " 'classes': tensor(0.0018),\n",
              " 'classroom': tensor(0.0850),\n",
              " 'clean': tensor(0.0329),\n",
              " 'clear': tensor(-0.0962),\n",
              " 'cleared': tensor(0.0873),\n",
              " 'clearing': tensor(-0.1286),\n",
              " 'clearly': tensor(0.0957),\n",
              " 'clicked': tensor(0.0638),\n",
              " 'climbed': tensor(0.1457),\n",
              " 'cloak': tensor(-0.0927),\n",
              " 'close': tensor(0.1556),\n",
              " 'closer': tensor(0.2278),\n",
              " 'clothes': tensor(-0.0523),\n",
              " 'club': tensor(0.1718),\n",
              " 'clutching': tensor(-0.0663),\n",
              " 'coat': tensor(0.1306),\n",
              " 'cold': tensor(-0.0757),\n",
              " 'come': tensor(0.0469),\n",
              " 'coming': tensor(-0.0320),\n",
              " 'common': tensor(0.1444),\n",
              " 'compartment': tensor(0.1381),\n",
              " 'completely': tensor(-0.0420),\n",
              " 'computer': tensor(0.0514),\n",
              " 'control': tensor(-0.0021),\n",
              " 'corner': tensor(0.0449),\n",
              " 'corridor': tensor(0.0826),\n",
              " 'corridors': tensor(-0.0076),\n",
              " 'could': tensor(0.0198),\n",
              " 'couldnt': tensor(0.0741),\n",
              " 'couple': tensor(0.0534),\n",
              " 'courage': tensor(0.1023),\n",
              " 'course': tensor(-0.0316),\n",
              " 'covered': tensor(0.0003),\n",
              " 'crabbe': tensor(0.1439),\n",
              " 'crack': tensor(-0.1221),\n",
              " 'crash': tensor(-0.0698),\n",
              " 'crate': tensor(0.0740),\n",
              " 'crept': tensor(-0.0750),\n",
              " 'cried': tensor(0.0945),\n",
              " 'cross': tensor(0.0191),\n",
              " 'crossed': tensor(-0.0405),\n",
              " 'crowd': tensor(0.0651),\n",
              " 'cry': tensor(0.0152),\n",
              " 'crying': tensor(-0.0829),\n",
              " 'cup': tensor(-0.0081),\n",
              " 'cupboard': tensor(-0.0734),\n",
              " 'curious': tensor(-0.2585),\n",
              " 'curse': tensor(-0.0593),\n",
              " 'cut': tensor(-0.0236),\n",
              " 'dad': tensor(-0.1478),\n",
              " 'damp': tensor(0.0560),\n",
              " 'dangerous': tensor(0.0072),\n",
              " 'dare': tensor(-0.2330),\n",
              " 'dark': tensor(0.0514),\n",
              " 'darkly': tensor(-0.0382),\n",
              " 'darkness': tensor(-0.0883),\n",
              " 'day': tensor(-0.2075),\n",
              " 'days': tensor(-0.0372),\n",
              " 'dead': tensor(-0.0732),\n",
              " 'dean': tensor(0.0814),\n",
              " 'dear': tensor(0.0091),\n",
              " 'death': tensor(-0.1178),\n",
              " 'decided': tensor(0.0807),\n",
              " 'deep': tensor(0.0098),\n",
              " 'delighted': tensor(-0.0660),\n",
              " 'desk': tensor(0.1164),\n",
              " 'desperate': tensor(0.0079),\n",
              " 'diagon': tensor(-0.0727),\n",
              " 'did': tensor(-0.0058),\n",
              " 'didnt': tensor(-0.0563),\n",
              " 'die': tensor(0.0453),\n",
              " 'died': tensor(0.0025),\n",
              " 'difference': tensor(0.1252),\n",
              " 'different': tensor(-0.0563),\n",
              " 'difficult': tensor(-0.0287),\n",
              " 'dinner': tensor(-0.0892),\n",
              " 'direction': tensor(0.0713),\n",
              " 'disappeared': tensor(0.0323),\n",
              " 'dived': tensor(0.0778),\n",
              " 'do': tensor(-0.1044),\n",
              " 'does': tensor(-0.0006),\n",
              " 'doesnt': tensor(0.0437),\n",
              " 'dog': tensor(-0.0578),\n",
              " 'dogs': tensor(-0.0315),\n",
              " 'doing': tensor(0.1497),\n",
              " 'don': tensor(0.0804),\n",
              " 'done': tensor(0.0465),\n",
              " 'dont': tensor(-0.0810),\n",
              " 'door': tensor(0.0717),\n",
              " 'doors': tensor(0.3216),\n",
              " 'doorway': tensor(-0.0676),\n",
              " 'dormitory': tensor(-0.0151),\n",
              " 'down': tensor(-0.1265),\n",
              " 'draco': tensor(-0.0080),\n",
              " 'dragged': tensor(-0.0073),\n",
              " 'dragon': tensor(0.1055),\n",
              " 'dragons': tensor(0.0759),\n",
              " 'dream': tensor(-0.0188),\n",
              " 'dressed': tensor(-0.1529),\n",
              " 'drew': tensor(0.1656),\n",
              " 'drills': tensor(-0.0674),\n",
              " 'drink': tensor(-0.1121),\n",
              " 'drive': tensor(-0.0267),\n",
              " 'drop': tensor(-0.0012),\n",
              " 'dropped': tensor(-0.0026),\n",
              " 'drove': tensor(-0.0609),\n",
              " 'dudley': tensor(-0.0648),\n",
              " 'dudleys': tensor(-0.0390),\n",
              " 'dumbledore': tensor(-0.0188),\n",
              " 'dumbledores': tensor(-0.0412),\n",
              " 'dungeons': tensor(0.2078),\n",
              " 'dunno': tensor(-0.0514),\n",
              " 'during': tensor(-0.1240),\n",
              " 'dursley': tensor(-0.1291),\n",
              " 'dursleys': tensor(-0.0400),\n",
              " 'each': tensor(0.1042),\n",
              " 'eagerly': tensor(-0.0857),\n",
              " 'ear': tensor(-0.1549),\n",
              " 'ears': tensor(-0.0600),\n",
              " 'earth': tensor(0.0349),\n",
              " 'easily': tensor(0.0017),\n",
              " 'easy': tensor(0.0951),\n",
              " 'eat': tensor(0.0194),\n",
              " 'eating': tensor(0.0506),\n",
              " 'edge': tensor(-0.1014),\n",
              " 'egg': tensor(0.0156),\n",
              " 'eh': tensor(0.0077),\n",
              " 'either': tensor(0.0094),\n",
              " 'eleven': tensor(-0.0273),\n",
              " 'else': tensor(0.0806),\n",
              " 'em': tensor(0.1387),\n",
              " 'empty': tensor(0.0737),\n",
              " 'end': tensor(-0.1099),\n",
              " 'enough': tensor(-0.0808),\n",
              " 'entered': tensor(0.0213),\n",
              " 'entrance': tensor(0.0186),\n",
              " 'envelope': tensor(0.0211),\n",
              " 'er': tensor(-0.0133),\n",
              " 'erised': tensor(-0.0954),\n",
              " 'even': tensor(-0.0954),\n",
              " 'evening': tensor(0.0618),\n",
              " 'ever': tensor(-0.0092),\n",
              " 'every': tensor(-0.1329),\n",
              " 'everybody': tensor(-0.0994),\n",
              " 'everyone': tensor(0.0486),\n",
              " 'everything': tensor(-0.0882),\n",
              " 'everywhere': tensor(0.0719),\n",
              " 'evil': tensor(0.0091),\n",
              " 'exactly': tensor(-0.1620),\n",
              " 'exam': tensor(-0.0692),\n",
              " 'exams': tensor(-0.0037),\n",
              " 'excellent': tensor(0.0340),\n",
              " 'except': tensor(-0.0880),\n",
              " 'excitedly': tensor(0.1334),\n",
              " 'excuse': tensor(-0.0334),\n",
              " 'expect': tensor(-0.0005),\n",
              " 'expected': tensor(0.0044),\n",
              " 'expelled': tensor(-0.2032),\n",
              " 'explain': tensor(-0.1946),\n",
              " 'extra': tensor(0.0332),\n",
              " 'eye': tensor(0.0646),\n",
              " 'eyes': tensor(0.1459),\n",
              " 'face': tensor(-0.0029),\n",
              " 'faces': tensor(0.0601),\n",
              " 'facing': tensor(0.0039),\n",
              " 'fact': tensor(-0.1111),\n",
              " 'faded': tensor(-0.1096),\n",
              " 'fall': tensor(0.0542),\n",
              " 'fallen': tensor(0.1812),\n",
              " 'families': tensor(-0.0507),\n",
              " 'family': tensor(-0.0882),\n",
              " 'famous': tensor(0.0377),\n",
              " 'fang': tensor(-0.2016),\n",
              " 'fangs': tensor(0.0556),\n",
              " 'far': tensor(-0.1265),\n",
              " 'fast': tensor(-0.0382),\n",
              " 'fat': tensor(0.0316),\n",
              " 'father': tensor(0.1207),\n",
              " 'fathers': tensor(0.1276),\n",
              " 'favorite': tensor(0.0781),\n",
              " 'fear': tensor(0.1157),\n",
              " 'feast': tensor(-0.0823),\n",
              " 'feather': tensor(-0.1492),\n",
              " 'feel': tensor(-0.0569),\n",
              " 'feeling': tensor(-0.0117),\n",
              " 'feet': tensor(-0.0616),\n",
              " 'fell': tensor(-0.0435),\n",
              " 'felt': tensor(0.0461),\n",
              " 'fer': tensor(0.0186),\n",
              " 'few': tensor(-0.0290),\n",
              " 'field': tensor(-0.0658),\n",
              " 'fifty': tensor(-0.0906),\n",
              " 'fight': tensor(0.0035),\n",
              " 'fighting': tensor(-0.0367),\n",
              " 'figure': tensor(-0.0730),\n",
              " 'filch': tensor(0.0172),\n",
              " 'filled': tensor(-0.0532),\n",
              " 'finally': tensor(0.0185),\n",
              " 'find': tensor(0.0718),\n",
              " 'finding': tensor(0.0132),\n",
              " 'fine': tensor(0.0449),\n",
              " 'fingers': tensor(-0.1406),\n",
              " 'finished': tensor(-0.0889),\n",
              " 'finnigan': tensor(0.1097),\n",
              " 'fire': tensor(0.0549),\n",
              " 'firenze': tensor(0.1573),\n",
              " 'firs': tensor(0.0609),\n",
              " 'first': tensor(-0.1667),\n",
              " 'five': tensor(-0.0171),\n",
              " 'fixed': tensor(0.0165),\n",
              " 'flamel': tensor(0.0834),\n",
              " 'flames': tensor(0.0247),\n",
              " 'flash': tensor(-0.2416),\n",
              " 'flat': tensor(-0.0703),\n",
              " 'flavor': tensor(-0.0149),\n",
              " 'flew': tensor(-0.0795),\n",
              " 'flint': tensor(0.1226),\n",
              " 'flitwick': tensor(-0.0704),\n",
              " 'floating': tensor(0.1527),\n",
              " 'floor': tensor(-0.1477),\n",
              " 'fluffy': tensor(-0.0476),\n",
              " 'flute': tensor(-0.0098),\n",
              " 'fly': tensor(0.0643),\n",
              " 'flying': tensor(-0.0723),\n",
              " 'follow': tensor(-0.1040),\n",
              " 'followed': tensor(0.0509),\n",
              " 'following': tensor(0.1565),\n",
              " 'food': tensor(-0.0441),\n",
              " 'foot': tensor(0.0102),\n",
              " 'footsteps': tensor(-0.0274),\n",
              " 'for': tensor(0.0603),\n",
              " 'forbidden': tensor(-0.0489),\n",
              " 'force': tensor(-0.0042),\n",
              " 'forehead': tensor(0.1002),\n",
              " 'forest': tensor(0.0521),\n",
              " 'forget': tensor(-0.2084),\n",
              " 'forgotten': tensor(-0.0499),\n",
              " 'forward': tensor(0.0370),\n",
              " 'found': tensor(-0.2615),\n",
              " 'four': tensor(-0.1759),\n",
              " 'fred': tensor(-0.1150),\n",
              " 'free': tensor(-0.0237),\n",
              " 'friend': tensor(0.0788),\n",
              " 'friends': tensor(0.0886),\n",
              " 'frog': tensor(0.1651),\n",
              " 'frogs': tensor(-0.1467),\n",
              " 'from': tensor(0.0097),\n",
              " 'front': tensor(-0.0173),\n",
              " 'full': tensor(0.0475),\n",
              " 'fun': tensor(-0.0814),\n",
              " 'funny': tensor(0.0168),\n",
              " 'furious': tensor(0.1180),\n",
              " 'furiously': tensor(-0.0197),\n",
              " 'game': tensor(0.0927),\n",
              " 'garden': tensor(0.0175),\n",
              " 'gasped': tensor(-0.1326),\n",
              " 'gave': tensor(-0.0075),\n",
              " 'gently': tensor(0.0481),\n",
              " 'george': tensor(-0.0521),\n",
              " 'get': tensor(-0.1498),\n",
              " 'gets': tensor(-0.1087),\n",
              " 'gettin': tensor(-0.0798),\n",
              " 'getting': tensor(0.0410),\n",
              " 'ghost': tensor(0.0377),\n",
              " 'ghosts': tensor(0.1276),\n",
              " 'giant': tensor(0.1147),\n",
              " 'girl': tensor(0.1894),\n",
              " 'girls': tensor(-0.0043),\n",
              " 'give': tensor(0.0924),\n",
              " 'given': tensor(-0.1106),\n",
              " 'giving': tensor(0.0565),\n",
              " 'glad': tensor(0.0333),\n",
              " 'glass': tensor(-0.0708),\n",
              " 'glasses': tensor(0.0001),\n",
              " 'go': tensor(-0.0988),\n",
              " 'goal': tensor(0.0755),\n",
              " 'goblin': tensor(0.0364),\n",
              " 'goblins': tensor(0.0559),\n",
              " 'goes': tensor(0.1688),\n",
              " 'going': tensor(-0.0317),\n",
              " 'gold': tensor(-0.0006),\n",
              " 'golden': tensor(-0.0805),\n",
              " 'gone': tensor(0.0469),\n",
              " 'good': tensor(-0.0788),\n",
              " 'goodbye': tensor(-0.0559),\n",
              " 'got': tensor(-0.2059),\n",
              " 'gotta': tensor(-0.2077),\n",
              " 'gotten': tensor(-0.0462),\n",
              " 'goyle': tensor(0.0742),\n",
              " 'grab': tensor(-0.1025),\n",
              " 'grabbed': tensor(-0.1122),\n",
              " 'granger': tensor(0.0336),\n",
              " 'grass': tensor(-0.1380),\n",
              " 'gray': tensor(-0.2089),\n",
              " 'great': tensor(0.0829),\n",
              " 'green': tensor(0.1411),\n",
              " 'grin': tensor(-0.0282),\n",
              " 'gringotts': tensor(-0.0522),\n",
              " 'griphook': tensor(0.0288),\n",
              " 'ground': tensor(0.1325),\n",
              " 'grounds': tensor(-0.0124),\n",
              " 'growled': tensor(-0.0241),\n",
              " 'grunted': tensor(0.0204),\n",
              " 'gryffindor': tensor(-0.0692),\n",
              " 'gryffindors': tensor(-0.0877),\n",
              " 'guard': tensor(-0.0899),\n",
              " 'guarding': tensor(-0.0996),\n",
              " 'h': tensor(-0.1630),\n",
              " 'had': tensor(0.0597),\n",
              " 'hadnt': tensor(-0.0586),\n",
              " 'hagrid': tensor(0.0440),\n",
              " 'hagrids': tensor(0.0707),\n",
              " 'hair': tensor(0.0115),\n",
              " 'half': tensor(-0.2063),\n",
              " 'halfway': tensor(0.0626),\n",
              " 'hall': tensor(0.0375),\n",
              " 'halloween': tensor(-0.0687),\n",
              " 'hand': tensor(0.1910),\n",
              " 'handed': tensor(0.0230),\n",
              " 'handle': tensor(0.2067),\n",
              " 'hands': tensor(0.0208),\n",
              " 'hang': tensor(0.0653),\n",
              " 'hanging': tensor(-0.0210),\n",
              " 'happen': tensor(0.0185),\n",
              " 'happened': tensor(-0.0542),\n",
              " 'happy': tensor(-0.0624),\n",
              " 'hard': tensor(-0.0062),\n",
              " 'harder': tensor(0.0070),\n",
              " 'hardly': tensor(0.0036),\n",
              " 'harry': tensor(0.9863),\n",
              " 'harrys': tensor(0.0076),\n",
              " 'has': tensor(0.1208),\n",
              " 'hasnt': tensor(0.0238),\n",
              " 'hat': tensor(-0.0724),\n",
              " 'hate': tensor(0.0008),\n",
              " 'hated': tensor(-0.0308),\n",
              " 'have': tensor(-0.0158),\n",
              " 'havent': tensor(-0.0850),\n",
              " 'having': tensor(-0.1362),\n",
              " 'he': tensor(-0.0876),\n",
              " 'head': tensor(0.2050),\n",
              " 'headless': tensor(0.1708),\n",
              " 'heads': tensor(-0.0060),\n",
              " 'hear': tensor(0.0078),\n",
              " 'heard': tensor(0.0306),\n",
              " 'heart': tensor(0.0345),\n",
              " 'heavy': tensor(0.1284),\n",
              " 'hed': tensor(0.0157),\n",
              " 'hedwig': tensor(-0.1808),\n",
              " 'held': tensor(0.0623),\n",
              " 'hell': tensor(0.1444),\n",
              " 'help': tensor(0.0030),\n",
              " 'her': tensor(0.0741),\n",
              " 'here': tensor(-0.1045),\n",
              " 'hermione': tensor(0.1467),\n",
              " 'hermiones': tensor(0.1320),\n",
              " 'herself': tensor(0.0710),\n",
              " 'hes': tensor(0.1618),\n",
              " 'hidden': tensor(0.0155),\n",
              " 'hide': tensor(0.0430),\n",
              " 'hiding': tensor(-0.2002),\n",
              " 'high': tensor(0.0643),\n",
              " 'higher': tensor(0.0095),\n",
              " 'him': tensor(0.0395),\n",
              " 'himself': tensor(0.2253),\n",
              " 'his': tensor(0.0198),\n",
              " 'hissed': tensor(0.1068),\n",
              " 'history': tensor(0.0005),\n",
              " 'hit': tensor(0.0165),\n",
              " 'hogwarts': tensor(0.0467),\n",
              " 'hold': tensor(0.0698),\n",
              " 'holding': tensor(-0.0970),\n",
              " 'hole': tensor(-0.0527),\n",
              " 'holidays': tensor(0.0120),\n",
              " 'home': tensor(0.0723),\n",
              " 'homework': tensor(0.0010),\n",
              " 'honestly': tensor(-0.0822),\n",
              " 'hooch': tensor(-0.1665),\n",
              " 'hoops': tensor(-0.1130),\n",
              " 'hope': tensor(-0.1702),\n",
              " 'hoping': tensor(-0.0624),\n",
              " 'horrible': tensor(0.0203),\n",
              " 'horror': tensor(-0.1199),\n",
              " 'hospital': tensor(0.0859),\n",
              " 'hot': tensor(0.0551),\n",
              " 'hour': tensor(0.1862),\n",
              " 'hours': tensor(-0.0434),\n",
              " 'house': tensor(0.0828),\n",
              " 'houses': tensor(-0.0142),\n",
              " 'how': tensor(-0.1053),\n",
              " 'however': tensor(-0.0402),\n",
              " 'howling': tensor(0.0853),\n",
              " 'hufflepuff': tensor(-0.2116),\n",
              " 'huge': tensor(-0.0004),\n",
              " 'human': tensor(-0.2739),\n",
              " 'hundred': tensor(-0.1891),\n",
              " 'hundreds': tensor(-0.1726),\n",
              " 'hung': tensor(0.0904),\n",
              " 'hungry': tensor(0.1059),\n",
              " 'hurried': tensor(-0.0949),\n",
              " 'hurry': tensor(-0.0759),\n",
              " 'hurrying': tensor(0.1272),\n",
              " 'hurt': tensor(-0.0894),\n",
              " 'hut': tensor(0.0406),\n",
              " 'i': tensor(0.1070),\n",
              " 'ice': tensor(0.0498),\n",
              " 'id': tensor(0.1223),\n",
              " 'idea': tensor(0.1626),\n",
              " 'if': tensor(0.0746),\n",
              " 'ignored': tensor(0.1793),\n",
              " 'ill': tensor(-0.0300),\n",
              " 'im': tensor(-0.0108),\n",
              " 'imagine': tensor(0.0976),\n",
              " 'important': tensor(0.0459),\n",
              " 'in': tensor(-0.0349),\n",
              " 'inches': tensor(-0.0170),\n",
              " 'indeed': tensor(0.0009),\n",
              " 'inside': tensor(0.0356),\n",
              " 'instead': tensor(0.0740),\n",
              " 'interested': tensor(-0.1462),\n",
              " 'interesting': tensor(0.0300),\n",
              " 'into': tensor(-0.0524),\n",
              " 'invisibility': tensor(0.0063),\n",
              " 'invisible': tensor(-0.0975),\n",
              " 'is': tensor(0.0296),\n",
              " 'isnt': tensor(0.1240),\n",
              " 'it': tensor(0.0323),\n",
              " 'itll': tensor(0.1529),\n",
              " 'its': tensor(0.1864),\n",
              " 'itself': tensor(-0.0253),\n",
              " 'ive': tensor(0.0641),\n",
              " 'jerked': tensor(0.0261),\n",
              " 'job': tensor(0.1566),\n",
              " 'join': tensor(-0.0053),\n",
              " 'joined': tensor(-0.0094),\n",
              " 'joke': tensor(-0.0114),\n",
              " 'jordan': tensor(0.0484),\n",
              " 'jump': tensor(0.0089),\n",
              " 'jumped': tensor(0.0764),\n",
              " 'jus': tensor(-0.0326),\n",
              " 'just': tensor(0.0355),\n",
              " 'keep': tensor(0.1552),\n",
              " 'keeper': tensor(0.0067),\n",
              " 'keeping': tensor(0.1986),\n",
              " 'kept': tensor(-0.0914),\n",
              " 'key': tensor(0.0513),\n",
              " 'keys': tensor(0.0799),\n",
              " 'kicked': tensor(0.0649),\n",
              " 'kill': tensor(0.0901),\n",
              " 'killed': tensor(-0.2030),\n",
              " 'kind': tensor(0.0852),\n",
              " 'kings': tensor(0.0979),\n",
              " 'kitchen': tensor(-0.1521),\n",
              " 'knees': tensor(0.0828),\n",
              " 'knew': tensor(0.0488),\n",
              " 'knight': tensor(0.0534),\n",
              " 'knock': tensor(0.0702),\n",
              " 'knocked': tensor(0.0075),\n",
              " 'knocking': tensor(0.0178),\n",
              " 'know': tensor(0.0852),\n",
              " 'knowing': tensor(-0.0783),\n",
              " 'known': tensor(0.0098),\n",
              " 'knows': tensor(-0.0503),\n",
              " 'knuts': tensor(0.0625),\n",
              " 'lady': tensor(-0.0502),\n",
              " 'lake': tensor(0.0290),\n",
              " 'lamp': tensor(-0.0126),\n",
              " 'landed': tensor(-0.0787),\n",
              " 'large': tensor(0.0176),\n",
              " 'last': tensor(-0.0047),\n",
              " 'late': tensor(0.0226),\n",
              " 'later': tensor(-0.1166),\n",
              " 'laugh': tensor(-0.0688),\n",
              " 'laughed': tensor(0.0770),\n",
              " 'laughing': tensor(0.0870),\n",
              " 'laughter': tensor(0.0946),\n",
              " 'lay': tensor(0.0013),\n",
              " 'lead': tensor(0.1022),\n",
              " 'leading': tensor(0.0395),\n",
              " 'leaky': tensor(0.0348),\n",
              " 'leaned': tensor(0.1614),\n",
              " 'leapt': tensor(-0.0724),\n",
              " 'learn': tensor(-0.0135),\n",
              " 'learned': tensor(-0.0322),\n",
              " 'least': tensor(-0.0344),\n",
              " 'leave': tensor(0.0784),\n",
              " 'leaves': tensor(0.0212),\n",
              " 'leaving': tensor(-0.0424),\n",
              " 'led': tensor(-0.1500),\n",
              " 'lee': tensor(0.0497),\n",
              " 'left': tensor(-0.0499),\n",
              " 'leg': tensor(0.0717),\n",
              " 'legs': tensor(0.0984),\n",
              " 'lemon': tensor(0.0013),\n",
              " 'less': tensor(0.1912),\n",
              " 'lesson': tensor(0.0059),\n",
              " 'lessons': tensor(-0.0397),\n",
              " 'let': tensor(0.0526),\n",
              " 'lets': tensor(0.0755),\n",
              " 'letter': tensor(0.0252),\n",
              " 'letters': tensor(-0.0379),\n",
              " 'library': tensor(0.1020),\n",
              " 'lie': tensor(0.0928),\n",
              " 'life': tensor(-0.0968),\n",
              " 'light': tensor(0.0605),\n",
              " 'lightning': tensor(0.0575),\n",
              " 'like': tensor(0.0008),\n",
              " 'liked': tensor(-0.1044),\n",
              " 'lily': tensor(-0.0024),\n",
              " 'line': tensor(-0.0455),\n",
              " 'lips': tensor(-0.1047),\n",
              " 'list': tensor(-0.0331),\n",
              " 'listen': tensor(0.0162),\n",
              " 'listening': tensor(0.0180),\n",
              " 'lit': tensor(0.1114),\n",
              " 'little': tensor(-0.1977),\n",
              " 'live': tensor(0.0975),\n",
              " 'lived': tensor(0.0165),\n",
              " 'living': tensor(0.0202),\n",
              " 'loads': tensor(0.1352),\n",
              " 'lock': tensor(0.0080),\n",
              " 'locked': tensor(0.0263),\n",
              " 'london': tensor(-0.1506),\n",
              " 'long': tensor(-0.0545),\n",
              " 'longbottom': tensor(0.0137),\n",
              " 'look': tensor(0.0362),\n",
              " 'looked': tensor(0.1041),\n",
              " 'looking': tensor(0.0603),\n",
              " 'looks': tensor(0.0293),\n",
              " 'lose': tensor(0.0331),\n",
              " 'losing': tensor(0.0292),\n",
              " 'lost': tensor(0.1278),\n",
              " 'lot': tensor(-0.0234),\n",
              " 'lots': tensor(0.1552),\n",
              " 'loud': tensor(-0.0302),\n",
              " 'loudly': tensor(-0.1424),\n",
              " 'low': tensor(0.0691),\n",
              " 'luck': tensor(-0.0165),\n",
              " 'lucky': tensor(-0.0054),\n",
              " 'lumpy': tensor(-0.2720),\n",
              " 'lurking': tensor(0.2021),\n",
              " 'lying': tensor(0.0515),\n",
              " 'mad': tensor(0.1067),\n",
              " 'madam': tensor(-0.2352),\n",
              " 'made': tensor(-0.0023),\n",
              " 'magic': tensor(-0.0864),\n",
              " 'magical': tensor(-0.0437),\n",
              " 'mail': tensor(-0.1063),\n",
              " 'make': tensor(0.0658),\n",
              " 'making': tensor(0.0209),\n",
              " 'malfoy': tensor(0.0310),\n",
              " 'malfoys': tensor(-0.0676),\n",
              " 'man': tensor(-0.0790),\n",
              " 'managed': tensor(-0.0220),\n",
              " 'many': tensor(-0.0856),\n",
              " 'marble': tensor(0.1302),\n",
              " 'marched': tensor(-0.0411),\n",
              " 'match': tensor(-0.0541),\n",
              " 'matter': tensor(0.0060),\n",
              " 'may': tensor(0.0968),\n",
              " 'maybe': tensor(0.0428),\n",
              " 'mcgonagall': tensor(0.0533),\n",
              " 'mcgonagalls': tensor(-0.1083),\n",
              " 'me': tensor(0.1614),\n",
              " 'mean': tensor(-0.0363),\n",
              " 'means': tensor(0.0348),\n",
              " 'meant': tensor(-0.1000),\n",
              " 'meet': tensor(-0.0094),\n",
              " 'mention': tensor(-0.3099),\n",
              " 'met': tensor(0.0416),\n",
              " 'midair': tensor(-0.0711),\n",
              " 'middle': tensor(0.0246),\n",
              " 'midnight': tensor(-0.0608),\n",
              " 'might': tensor(0.1011),\n",
              " 'mind': tensor(0.0247),\n",
              " 'ministry': tensor(0.2240),\n",
              " 'minute': tensor(-0.0639),\n",
              " 'minutes': tensor(-0.0680),\n",
              " 'mirror': tensor(-0.0950),\n",
              " 'miss': tensor(0.0910),\n",
              " 'mistake': tensor(0.1461),\n",
              " 'moaned': tensor(-0.0943),\n",
              " 'mom': tensor(0.0024),\n",
              " 'moment': tensor(0.1804),\n",
              " 'money': tensor(0.1331),\n",
              " 'moonlight': tensor(0.0452),\n",
              " 'more': tensor(-0.0029),\n",
              " 'morning': tensor(-0.0216),\n",
              " 'most': tensor(-0.0472),\n",
              " 'mother': tensor(0.0672),\n",
              " 'mothers': tensor(-0.0307),\n",
              " 'motorcycle': tensor(-0.1754),\n",
              " 'mountain': tensor(0.2008),\n",
              " 'mouth': tensor(0.0268),\n",
              " 'move': tensor(0.1185),\n",
              " 'moved': tensor(0.0411),\n",
              " 'moving': tensor(-0.0594),\n",
              " 'mr': tensor(-0.1077),\n",
              " 'mrs': tensor(0.1476),\n",
              " 'much': tensor(0.1140),\n",
              " 'muggle': tensor(-0.0477),\n",
              " 'muggles': tensor(-0.0178),\n",
              " 'murmured': tensor(0.1034),\n",
              " 'must': tensor(-0.0328),\n",
              " 'mustache': tensor(-0.1050),\n",
              " 'mustve': tensor(-0.1284),\n",
              " 'muttered': tensor(0.0439),\n",
              " 'muttering': tensor(0.0137),\n",
              " 'my': tensor(0.0264),\n",
              " 'myself': tensor(0.1081),\n",
              " 'mysterious': tensor(-0.0046),\n",
              " 'nah': tensor(-0.0312),\n",
              " 'name': tensor(-0.0749),\n",
              " 'names': tensor(-0.0253),\n",
              " 'narrow': tensor(-0.0178),\n",
              " 'nasty': tensor(-0.0166),\n",
              " 'near': tensor(-0.0795),\n",
              " 'nearer': tensor(-0.0550),\n",
              " 'nearest': tensor(0.0443),\n",
              " 'nearly': tensor(0.0731),\n",
              " 'neck': tensor(-0.0269),\n",
              " 'need': tensor(-0.0239),\n",
              " 'needed': tensor(0.1431),\n",
              " 'needs': tensor(0.1019),\n",
              " 'neither': tensor(-0.0497),\n",
              " 'nervous': tensor(-0.1600),\n",
              " 'nervously': tensor(0.1114),\n",
              " 'never': tensor(0.0603),\n",
              " 'neville': tensor(0.0379),\n",
              " 'nevilles': tensor(-0.0888),\n",
              " 'new': tensor(0.0459),\n",
              " 'news': tensor(-0.0444),\n",
              " 'newspaper': tensor(0.0366),\n",
              " 'next': tensor(0.0649),\n",
              " 'nice': tensor(0.0108),\n",
              " 'nicolas': tensor(-0.0667),\n",
              " 'night': tensor(-0.1342),\n",
              " 'nimbus': tensor(0.1067),\n",
              " 'nine': tensor(0.0264),\n",
              " 'no': tensor(0.0275),\n",
              " 'nobody': tensor(0.0058),\n",
              " 'nodded': tensor(-0.0132),\n",
              " 'noise': tensor(-0.0179),\n",
              " 'none': tensor(0.0950),\n",
              " 'nor': tensor(-0.0626),\n",
              " 'norbert': tensor(-0.0744),\n",
              " 'normal': tensor(0.0760),\n",
              " 'norris': tensor(0.0664),\n",
              " 'nose': tensor(0.0024),\n",
              " 'noses': tensor(-0.1323),\n",
              " 'nostrils': tensor(0.0804),\n",
              " 'not': tensor(-0.0046),\n",
              " 'note': tensor(-0.0627),\n",
              " 'notes': tensor(0.1427),\n",
              " 'nothin': tensor(-0.0055),\n",
              " 'nothing': tensor(-0.0750),\n",
              " 'notice': tensor(0.0070),\n",
              " 'noticed': tensor(-0.0506),\n",
              " 'noticing': tensor(-0.0502),\n",
              " 'now': tensor(-0.1090),\n",
              " 'number': tensor(0.2148),\n",
              " 'o': tensor(-0.0817),\n",
              " 'obviously': tensor(0.1204),\n",
              " 'oclock': tensor(0.0512),\n",
              " 'odd': tensor(0.0663),\n",
              " 'of': tensor(-0.1076),\n",
              " 'off': tensor(0.0152),\n",
              " 'often': tensor(-0.0482),\n",
              " 'oh': tensor(-0.0676),\n",
              " 'old': tensor(-0.0977),\n",
              " 'older': tensor(0.0939),\n",
              " 'ollivander': tensor(-0.1040),\n",
              " 'on': tensor(-0.1220),\n",
              " 'once': tensor(-0.0421),\n",
              " 'one': tensor(-0.1972),\n",
              " 'ones': tensor(0.1786),\n",
              " 'only': tensor(0.0400),\n",
              " 'onto': tensor(0.0872),\n",
              " 'open': tensor(0.0043),\n",
              " 'opened': tensor(0.0305),\n",
              " 'opposite': tensor(-0.0610),\n",
              " 'or': tensor(-0.0151),\n",
              " 'ordinary': tensor(-0.1335),\n",
              " 'other': tensor(-0.1448),\n",
              " 'others': tensor(0.0177),\n",
              " 'our': tensor(-0.0608),\n",
              " 'out': tensor(-0.0664),\n",
              " 'outside': tensor(-0.1048),\n",
              " 'outta': tensor(0.0899),\n",
              " 'over': tensor(0.0812),\n",
              " 'overhead': tensor(-0.0235),\n",
              " 'owl': tensor(-0.0565),\n",
              " 'owls': tensor(-0.0386),\n",
              " 'own': tensor(-0.0532),\n",
              " 'pack': tensor(0.0207),\n",
              " 'package': tensor(-0.0779),\n",
              " 'packed': tensor(-0.1788),\n",
              " 'pain': tensor(0.0101),\n",
              " 'pair': tensor(-0.0676),\n",
              " 'pale': tensor(0.0246),\n",
              " 'panted': tensor(-0.0207),\n",
              " 'paper': tensor(0.0124),\n",
              " 'parcel': tensor(-0.0398),\n",
              " 'parchment': tensor(-0.1498),\n",
              " 'parents': tensor(0.0975),\n",
              " 'particularly': tensor(0.0633),\n",
              " 'passageway': tensor(0.0274),\n",
              " 'passed': tensor(-0.0601),\n",
              " 'passing': tensor(-0.0099),\n",
              " 'past': tensor(-0.1828),\n",
              " 'path': tensor(0.0313),\n",
              " 'patil': tensor(0.0529),\n",
              " 'peered': tensor(-0.0097),\n",
              " 'peering': tensor(-0.0839),\n",
              " 'peeves': tensor(0.0037),\n",
              " 'people': tensor(0.0627),\n",
              " 'percy': tensor(-0.0175),\n",
              " 'perfect': tensor(0.0049),\n",
              " 'perhaps': tensor(-0.1081),\n",
              " 'person': tensor(0.0879),\n",
              " 'petunia': tensor(0.0520),\n",
              " 'picked': tensor(0.0246),\n",
              " 'piece': tensor(-0.0041),\n",
              " 'pieces': tensor(0.1343),\n",
              " 'piers': tensor(0.0431),\n",
              " 'pig': tensor(-0.1537),\n",
              " 'pile': tensor(0.1179),\n",
              " 'piled': tensor(-0.0923),\n",
              " 'pink': tensor(0.0681),\n",
              " 'pinned': tensor(-0.0396),\n",
              " 'place': tensor(0.0024),\n",
              " 'planets': tensor(-0.1230),\n",
              " 'plant': tensor(-0.0199),\n",
              " 'plates': tensor(0.0015),\n",
              " 'platform': tensor(-0.0011),\n",
              " 'platforms': tensor(-0.0949),\n",
              " 'play': tensor(0.0799),\n",
              " 'players': tensor(0.0026),\n",
              " 'playing': tensor(0.0516),\n",
              " 'please': tensor(-0.0358),\n",
              " 'pleased': tensor(0.0678),\n",
              " 'pocket': tensor(0.0533),\n",
              " 'pockets': tensor(-0.0979),\n",
              " 'point': tensor(0.1363),\n",
              " 'pointed': tensor(-0.0440),\n",
              " 'pointing': tensor(-0.1033),\n",
              " 'points': tensor(-0.0530),\n",
              " 'pomfrey': tensor(-0.1433),\n",
              " 'poor': tensor(-0.0276),\n",
              " 'portrait': tensor(-0.0380),\n",
              " 'possession': tensor(0.0603),\n",
              " 'possible': tensor(-0.0968),\n",
              " 'posts': tensor(0.0837),\n",
              " 'potion': tensor(-0.0349),\n",
              " 'potions': tensor(0.0099),\n",
              " 'potter': tensor(-0.0057),\n",
              " 'potters': tensor(0.0715),\n",
              " 'power': tensor(0.0041),\n",
              " 'powerful': tensor(-0.1982),\n",
              " 'practice': tensor(-0.0219),\n",
              " 'prefect': tensor(0.1000),\n",
              " 'prefects': tensor(-0.1029),\n",
              " 'presents': tensor(-0.0261),\n",
              " 'pressed': tensor(-0.0684),\n",
              " 'privet': tensor(-0.1279),\n",
              " 'probably': tensor(0.0493),\n",
              " 'professor': tensor(0.0571),\n",
              " 'properly': tensor(0.0599),\n",
              " 'proud': tensor(-0.1126),\n",
              " 'pull': tensor(0.1682),\n",
              " 'pulled': tensor(-0.0214),\n",
              " 'pulling': tensor(-0.1083),\n",
              " 'purple': tensor(-0.0351),\n",
              " 'pushed': tensor(-0.0268),\n",
              " 'put': tensor(-0.0730),\n",
              " 'quaffle': tensor(0.1244),\n",
              " 'question': tensor(-0.0024),\n",
              " 'questions': tensor(0.0964),\n",
              " 'quick': tensor(0.0352),\n",
              " 'quickly': tensor(0.0454),\n",
              " 'quidditch': tensor(0.0397),\n",
              " 'quiet': tensor(0.1743),\n",
              " 'quietly': tensor(0.1487),\n",
              " 'quills': tensor(0.0660),\n",
              " 'quirrell': tensor(0.1864),\n",
              " 'quirrells': tensor(0.0440),\n",
              " 'quite': tensor(0.0048),\n",
              " 'racing': tensor(0.0504),\n",
              " 'raised': tensor(0.2084),\n",
              " 'ran': tensor(-0.0602),\n",
              " 'rang': tensor(0.0998),\n",
              " 'rat': tensor(-0.0617),\n",
              " 'rather': tensor(0.0698),\n",
              " 'ravenclaw': tensor(0.0910),\n",
              " 'reached': tensor(0.0229),\n",
              " 'read': tensor(-0.0114),\n",
              " 'ready': tensor(-0.0662),\n",
              " 'real': tensor(-0.0761),\n",
              " 'realize': tensor(0.2163),\n",
              " 'realized': tensor(0.0118),\n",
              " 'really': tensor(0.0321),\n",
              " 'reason': tensor(-0.0988),\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# we can get the dot product value for every other words in the vocab\n",
        "# to get  P(word | harry)\n",
        "word_dot_dict = {}\n",
        "for word in filtered_vocab:\n",
        "  w_idx = word2idx[word]\n",
        "  w_vector = word_vectors[w_idx]\n",
        "  word_dot_dict[word] = sum(harry * w_vector)\n",
        "word_dot_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQzYZK-gkzqe"
      },
      "source": [
        "Now, let's convert these dot products to probabilities using the softmax function:\n",
        "- We have to convert our prediction into probability distribution to get P(word|harry) so that sum of [P(a|harry), ..., P(potter|harry), ... P(ron|harry), ... ] = 1\n",
        "- current dot product value is any real number, sometimes called as logit\n",
        "  - logit from logistic regression. Some values that are not yet converted to 0-1 or value before sigmoid function\n",
        "  - every probability should be in range (0, 1) (greater than 0, smaller than 1)\n",
        "  - this can be handled by taking exponential of dot product values, divided by total sum\n",
        "  - This function is called **Softmax**\n",
        "\n",
        "- Why we use exponential?\n",
        "  - Because we want to make every probability in positive range while preserving the order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DQ1PUvuLyv6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c9871af0-63c6-45c9-ce57-b4c3e183c0ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': tensor(0.0006),\n",
              " 'able': tensor(0.0007),\n",
              " 'abou': tensor(0.0007),\n",
              " 'about': tensor(0.0008),\n",
              " 'above': tensor(0.0008),\n",
              " 'across': tensor(0.0007),\n",
              " 'added': tensor(0.0008),\n",
              " 'afford': tensor(0.0006),\n",
              " 'afraid': tensor(0.0007),\n",
              " 'after': tensor(0.0007),\n",
              " 'afternoon': tensor(0.0007),\n",
              " 'again': tensor(0.0006),\n",
              " 'against': tensor(0.0007),\n",
              " 'ages': tensor(0.0007),\n",
              " 'ago': tensor(0.0006),\n",
              " 'agreed': tensor(0.0007),\n",
              " 'ah': tensor(0.0007),\n",
              " 'ahead': tensor(0.0006),\n",
              " 'air': tensor(0.0007),\n",
              " 'albus': tensor(0.0007),\n",
              " 'alive': tensor(0.0007),\n",
              " 'all': tensor(0.0007),\n",
              " 'alley': tensor(0.0007),\n",
              " 'allowed': tensor(0.0008),\n",
              " 'almost': tensor(0.0007),\n",
              " 'alone': tensor(0.0007),\n",
              " 'along': tensor(0.0007),\n",
              " 'already': tensor(0.0006),\n",
              " 'also': tensor(0.0007),\n",
              " 'although': tensor(0.0006),\n",
              " 'always': tensor(0.0008),\n",
              " 'am': tensor(0.0006),\n",
              " 'an': tensor(0.0007),\n",
              " 'and': tensor(0.0007),\n",
              " 'angrily': tensor(0.0007),\n",
              " 'angry': tensor(0.0007),\n",
              " 'another': tensor(0.0007),\n",
              " 'answer': tensor(0.0007),\n",
              " 'any': tensor(0.0006),\n",
              " 'anymore': tensor(0.0006),\n",
              " 'anyone': tensor(0.0005),\n",
              " 'anythin': tensor(0.0006),\n",
              " 'anything': tensor(0.0007),\n",
              " 'anyway': tensor(0.0007),\n",
              " 'anywhere': tensor(0.0006),\n",
              " 'apart': tensor(0.0007),\n",
              " 'appeared': tensor(0.0007),\n",
              " 'are': tensor(0.0007),\n",
              " 'arent': tensor(0.0006),\n",
              " 'arm': tensor(0.0007),\n",
              " 'armor': tensor(0.0006),\n",
              " 'arms': tensor(0.0007),\n",
              " 'around': tensor(0.0005),\n",
              " 'arrived': tensor(0.0006),\n",
              " 'arts': tensor(0.0007),\n",
              " 'as': tensor(0.0005),\n",
              " 'ask': tensor(0.0006),\n",
              " 'asked': tensor(0.0007),\n",
              " 'asking': tensor(0.0007),\n",
              " 'asleep': tensor(0.0007),\n",
              " 'at': tensor(0.0007),\n",
              " 'attention': tensor(0.0006),\n",
              " 'aunt': tensor(0.0006),\n",
              " 'awake': tensor(0.0006),\n",
              " 'away': tensor(0.0007),\n",
              " 'baby': tensor(0.0006),\n",
              " 'back': tensor(0.0006),\n",
              " 'backward': tensor(0.0007),\n",
              " 'bacon': tensor(0.0008),\n",
              " 'bad': tensor(0.0006),\n",
              " 'bag': tensor(0.0007),\n",
              " 'ball': tensor(0.0007),\n",
              " 'balls': tensor(0.0007),\n",
              " 'bane': tensor(0.0007),\n",
              " 'barrier': tensor(0.0006),\n",
              " 'be': tensor(0.0007),\n",
              " 'beans': tensor(0.0006),\n",
              " 'beard': tensor(0.0006),\n",
              " 'became': tensor(0.0006),\n",
              " 'because': tensor(0.0007),\n",
              " 'become': tensor(0.0006),\n",
              " 'bed': tensor(0.0006),\n",
              " 'bedroom': tensor(0.0007),\n",
              " 'been': tensor(0.0006),\n",
              " 'before': tensor(0.0006),\n",
              " 'began': tensor(0.0008),\n",
              " 'behind': tensor(0.0007),\n",
              " 'being': tensor(0.0007),\n",
              " 'believe': tensor(0.0006),\n",
              " 'below': tensor(0.0006),\n",
              " 'beneath': tensor(0.0007),\n",
              " 'bent': tensor(0.0006),\n",
              " 'best': tensor(0.0007),\n",
              " 'bet': tensor(0.0008),\n",
              " 'better': tensor(0.0007),\n",
              " 'between': tensor(0.0007),\n",
              " 'big': tensor(0.0007),\n",
              " 'bill': tensor(0.0006),\n",
              " 'bin': tensor(0.0006),\n",
              " 'binoculars': tensor(0.0006),\n",
              " 'birthday': tensor(0.0007),\n",
              " 'bit': tensor(0.0007),\n",
              " 'black': tensor(0.0007),\n",
              " 'blankets': tensor(0.0006),\n",
              " 'blew': tensor(0.0008),\n",
              " 'blood': tensor(0.0006),\n",
              " 'bloody': tensor(0.0007),\n",
              " 'bludger': tensor(0.0007),\n",
              " 'bludgers': tensor(0.0007),\n",
              " 'blue': tensor(0.0007),\n",
              " 'board': tensor(0.0007),\n",
              " 'boat': tensor(0.0007),\n",
              " 'boats': tensor(0.0006),\n",
              " 'body': tensor(0.0006),\n",
              " 'book': tensor(0.0008),\n",
              " 'books': tensor(0.0006),\n",
              " 'both': tensor(0.0007),\n",
              " 'bottle': tensor(0.0008),\n",
              " 'bottles': tensor(0.0006),\n",
              " 'bottom': tensor(0.0006),\n",
              " 'bought': tensor(0.0006),\n",
              " 'bowed': tensor(0.0008),\n",
              " 'box': tensor(0.0006),\n",
              " 'boy': tensor(0.0006),\n",
              " 'boys': tensor(0.0007),\n",
              " 'branches': tensor(0.0006),\n",
              " 'brave': tensor(0.0008),\n",
              " 'break': tensor(0.0007),\n",
              " 'breakfast': tensor(0.0006),\n",
              " 'breaking': tensor(0.0006),\n",
              " 'breath': tensor(0.0007),\n",
              " 'breathing': tensor(0.0006),\n",
              " 'bright': tensor(0.0008),\n",
              " 'brilliant': tensor(0.0006),\n",
              " 'broke': tensor(0.0006),\n",
              " 'broken': tensor(0.0007),\n",
              " 'broom': tensor(0.0006),\n",
              " 'brooms': tensor(0.0007),\n",
              " 'broomstick': tensor(0.0007),\n",
              " 'broomsticks': tensor(0.0006),\n",
              " 'brother': tensor(0.0007),\n",
              " 'brothers': tensor(0.0007),\n",
              " 'brought': tensor(0.0008),\n",
              " 'brown': tensor(0.0005),\n",
              " 'burst': tensor(0.0007),\n",
              " 'business': tensor(0.0007),\n",
              " 'busy': tensor(0.0006),\n",
              " 'but': tensor(0.0006),\n",
              " 'buy': tensor(0.0007),\n",
              " 'by': tensor(0.0006),\n",
              " 'cake': tensor(0.0007),\n",
              " 'cakes': tensor(0.0008),\n",
              " 'call': tensor(0.0008),\n",
              " 'called': tensor(0.0006),\n",
              " 'came': tensor(0.0006),\n",
              " 'can': tensor(0.0006),\n",
              " 'cant': tensor(0.0007),\n",
              " 'car': tensor(0.0008),\n",
              " 'card': tensor(0.0006),\n",
              " 'care': tensor(0.0006),\n",
              " 'careful': tensor(0.0006),\n",
              " 'carefully': tensor(0.0007),\n",
              " 'carried': tensor(0.0007),\n",
              " 'carrying': tensor(0.0007),\n",
              " 'cart': tensor(0.0007),\n",
              " 'case': tensor(0.0006),\n",
              " 'castle': tensor(0.0007),\n",
              " 'cat': tensor(0.0007),\n",
              " 'catch': tensor(0.0006),\n",
              " 'cats': tensor(0.0007),\n",
              " 'caught': tensor(0.0006),\n",
              " 'cauldron': tensor(0.0006),\n",
              " 'cause': tensor(0.0006),\n",
              " 'ceiling': tensor(0.0006),\n",
              " 'centaur': tensor(0.0007),\n",
              " 'certainly': tensor(0.0007),\n",
              " 'chair': tensor(0.0007),\n",
              " 'chamber': tensor(0.0006),\n",
              " 'chance': tensor(0.0006),\n",
              " 'change': tensor(0.0006),\n",
              " 'changed': tensor(0.0007),\n",
              " 'chapter': tensor(0.0007),\n",
              " 'charlie': tensor(0.0007),\n",
              " 'charlies': tensor(0.0007),\n",
              " 'charms': tensor(0.0007),\n",
              " 'chasers': tensor(0.0007),\n",
              " 'cheer': tensor(0.0007),\n",
              " 'cheering': tensor(0.0006),\n",
              " 'cheers': tensor(0.0008),\n",
              " 'chess': tensor(0.0007),\n",
              " 'chessmen': tensor(0.0006),\n",
              " 'chest': tensor(0.0006),\n",
              " 'chocolate': tensor(0.0006),\n",
              " 'christmas': tensor(0.0007),\n",
              " 'chuckled': tensor(0.0007),\n",
              " 'clambered': tensor(0.0005),\n",
              " 'clapped': tensor(0.0008),\n",
              " 'class': tensor(0.0008),\n",
              " 'classes': tensor(0.0007),\n",
              " 'classroom': tensor(0.0007),\n",
              " 'clean': tensor(0.0007),\n",
              " 'clear': tensor(0.0006),\n",
              " 'cleared': tensor(0.0007),\n",
              " 'clearing': tensor(0.0006),\n",
              " 'clearly': tensor(0.0007),\n",
              " 'clicked': tensor(0.0007),\n",
              " 'climbed': tensor(0.0008),\n",
              " 'cloak': tensor(0.0006),\n",
              " 'close': tensor(0.0008),\n",
              " 'closer': tensor(0.0008),\n",
              " 'clothes': tensor(0.0006),\n",
              " 'club': tensor(0.0008),\n",
              " 'clutching': tensor(0.0006),\n",
              " 'coat': tensor(0.0008),\n",
              " 'cold': tensor(0.0006),\n",
              " 'come': tensor(0.0007),\n",
              " 'coming': tensor(0.0006),\n",
              " 'common': tensor(0.0008),\n",
              " 'compartment': tensor(0.0008),\n",
              " 'completely': tensor(0.0006),\n",
              " 'computer': tensor(0.0007),\n",
              " 'control': tensor(0.0007),\n",
              " 'corner': tensor(0.0007),\n",
              " 'corridor': tensor(0.0007),\n",
              " 'corridors': tensor(0.0007),\n",
              " 'could': tensor(0.0007),\n",
              " 'couldnt': tensor(0.0007),\n",
              " 'couple': tensor(0.0007),\n",
              " 'courage': tensor(0.0007),\n",
              " 'course': tensor(0.0006),\n",
              " 'covered': tensor(0.0007),\n",
              " 'crabbe': tensor(0.0008),\n",
              " 'crack': tensor(0.0006),\n",
              " 'crash': tensor(0.0006),\n",
              " 'crate': tensor(0.0007),\n",
              " 'crept': tensor(0.0006),\n",
              " 'cried': tensor(0.0007),\n",
              " 'cross': tensor(0.0007),\n",
              " 'crossed': tensor(0.0006),\n",
              " 'crowd': tensor(0.0007),\n",
              " 'cry': tensor(0.0007),\n",
              " 'crying': tensor(0.0006),\n",
              " 'cup': tensor(0.0007),\n",
              " 'cupboard': tensor(0.0006),\n",
              " 'curious': tensor(0.0005),\n",
              " 'curse': tensor(0.0006),\n",
              " 'cut': tensor(0.0006),\n",
              " 'dad': tensor(0.0006),\n",
              " 'damp': tensor(0.0007),\n",
              " 'dangerous': tensor(0.0007),\n",
              " 'dare': tensor(0.0005),\n",
              " 'dark': tensor(0.0007),\n",
              " 'darkly': tensor(0.0006),\n",
              " 'darkness': tensor(0.0006),\n",
              " 'day': tensor(0.0005),\n",
              " 'days': tensor(0.0006),\n",
              " 'dead': tensor(0.0006),\n",
              " 'dean': tensor(0.0007),\n",
              " 'dear': tensor(0.0007),\n",
              " 'death': tensor(0.0006),\n",
              " 'decided': tensor(0.0007),\n",
              " 'deep': tensor(0.0007),\n",
              " 'delighted': tensor(0.0006),\n",
              " 'desk': tensor(0.0007),\n",
              " 'desperate': tensor(0.0007),\n",
              " 'diagon': tensor(0.0006),\n",
              " 'did': tensor(0.0007),\n",
              " 'didnt': tensor(0.0006),\n",
              " 'die': tensor(0.0007),\n",
              " 'died': tensor(0.0007),\n",
              " 'difference': tensor(0.0007),\n",
              " 'different': tensor(0.0006),\n",
              " 'difficult': tensor(0.0006),\n",
              " 'dinner': tensor(0.0006),\n",
              " 'direction': tensor(0.0007),\n",
              " 'disappeared': tensor(0.0007),\n",
              " 'dived': tensor(0.0007),\n",
              " 'do': tensor(0.0006),\n",
              " 'does': tensor(0.0007),\n",
              " 'doesnt': tensor(0.0007),\n",
              " 'dog': tensor(0.0006),\n",
              " 'dogs': tensor(0.0006),\n",
              " 'doing': tensor(0.0008),\n",
              " 'don': tensor(0.0007),\n",
              " 'done': tensor(0.0007),\n",
              " 'dont': tensor(0.0006),\n",
              " 'door': tensor(0.0007),\n",
              " 'doors': tensor(0.0009),\n",
              " 'doorway': tensor(0.0006),\n",
              " 'dormitory': tensor(0.0006),\n",
              " 'down': tensor(0.0006),\n",
              " 'draco': tensor(0.0007),\n",
              " 'dragged': tensor(0.0007),\n",
              " 'dragon': tensor(0.0007),\n",
              " 'dragons': tensor(0.0007),\n",
              " 'dream': tensor(0.0006),\n",
              " 'dressed': tensor(0.0006),\n",
              " 'drew': tensor(0.0008),\n",
              " 'drills': tensor(0.0006),\n",
              " 'drink': tensor(0.0006),\n",
              " 'drive': tensor(0.0006),\n",
              " 'drop': tensor(0.0007),\n",
              " 'dropped': tensor(0.0007),\n",
              " 'drove': tensor(0.0006),\n",
              " 'dudley': tensor(0.0006),\n",
              " 'dudleys': tensor(0.0006),\n",
              " 'dumbledore': tensor(0.0006),\n",
              " 'dumbledores': tensor(0.0006),\n",
              " 'dungeons': tensor(0.0008),\n",
              " 'dunno': tensor(0.0006),\n",
              " 'during': tensor(0.0006),\n",
              " 'dursley': tensor(0.0006),\n",
              " 'dursleys': tensor(0.0006),\n",
              " 'each': tensor(0.0007),\n",
              " 'eagerly': tensor(0.0006),\n",
              " 'ear': tensor(0.0006),\n",
              " 'ears': tensor(0.0006),\n",
              " 'earth': tensor(0.0007),\n",
              " 'easily': tensor(0.0007),\n",
              " 'easy': tensor(0.0007),\n",
              " 'eat': tensor(0.0007),\n",
              " 'eating': tensor(0.0007),\n",
              " 'edge': tensor(0.0006),\n",
              " 'egg': tensor(0.0007),\n",
              " 'eh': tensor(0.0007),\n",
              " 'either': tensor(0.0007),\n",
              " 'eleven': tensor(0.0006),\n",
              " 'else': tensor(0.0007),\n",
              " 'em': tensor(0.0008),\n",
              " 'empty': tensor(0.0007),\n",
              " 'end': tensor(0.0006),\n",
              " 'enough': tensor(0.0006),\n",
              " 'entered': tensor(0.0007),\n",
              " 'entrance': tensor(0.0007),\n",
              " 'envelope': tensor(0.0007),\n",
              " 'er': tensor(0.0007),\n",
              " 'erised': tensor(0.0006),\n",
              " 'even': tensor(0.0006),\n",
              " 'evening': tensor(0.0007),\n",
              " 'ever': tensor(0.0007),\n",
              " 'every': tensor(0.0006),\n",
              " 'everybody': tensor(0.0006),\n",
              " 'everyone': tensor(0.0007),\n",
              " 'everything': tensor(0.0006),\n",
              " 'everywhere': tensor(0.0007),\n",
              " 'evil': tensor(0.0007),\n",
              " 'exactly': tensor(0.0006),\n",
              " 'exam': tensor(0.0006),\n",
              " 'exams': tensor(0.0007),\n",
              " 'excellent': tensor(0.0007),\n",
              " 'except': tensor(0.0006),\n",
              " 'excitedly': tensor(0.0008),\n",
              " 'excuse': tensor(0.0006),\n",
              " 'expect': tensor(0.0007),\n",
              " 'expected': tensor(0.0007),\n",
              " 'expelled': tensor(0.0005),\n",
              " 'explain': tensor(0.0005),\n",
              " 'extra': tensor(0.0007),\n",
              " 'eye': tensor(0.0007),\n",
              " 'eyes': tensor(0.0008),\n",
              " 'face': tensor(0.0007),\n",
              " 'faces': tensor(0.0007),\n",
              " 'facing': tensor(0.0007),\n",
              " 'fact': tensor(0.0006),\n",
              " 'faded': tensor(0.0006),\n",
              " 'fall': tensor(0.0007),\n",
              " 'fallen': tensor(0.0008),\n",
              " 'families': tensor(0.0006),\n",
              " 'family': tensor(0.0006),\n",
              " 'famous': tensor(0.0007),\n",
              " 'fang': tensor(0.0005),\n",
              " 'fangs': tensor(0.0007),\n",
              " 'far': tensor(0.0006),\n",
              " 'fast': tensor(0.0006),\n",
              " 'fat': tensor(0.0007),\n",
              " 'father': tensor(0.0007),\n",
              " 'fathers': tensor(0.0007),\n",
              " 'favorite': tensor(0.0007),\n",
              " 'fear': tensor(0.0007),\n",
              " 'feast': tensor(0.0006),\n",
              " 'feather': tensor(0.0006),\n",
              " 'feel': tensor(0.0006),\n",
              " 'feeling': tensor(0.0007),\n",
              " 'feet': tensor(0.0006),\n",
              " 'fell': tensor(0.0006),\n",
              " 'felt': tensor(0.0007),\n",
              " 'fer': tensor(0.0007),\n",
              " 'few': tensor(0.0006),\n",
              " 'field': tensor(0.0006),\n",
              " 'fifty': tensor(0.0006),\n",
              " 'fight': tensor(0.0007),\n",
              " 'fighting': tensor(0.0006),\n",
              " 'figure': tensor(0.0006),\n",
              " 'filch': tensor(0.0007),\n",
              " 'filled': tensor(0.0006),\n",
              " 'finally': tensor(0.0007),\n",
              " 'find': tensor(0.0007),\n",
              " 'finding': tensor(0.0007),\n",
              " 'fine': tensor(0.0007),\n",
              " 'fingers': tensor(0.0006),\n",
              " 'finished': tensor(0.0006),\n",
              " 'finnigan': tensor(0.0007),\n",
              " 'fire': tensor(0.0007),\n",
              " 'firenze': tensor(0.0008),\n",
              " 'firs': tensor(0.0007),\n",
              " 'first': tensor(0.0006),\n",
              " 'five': tensor(0.0006),\n",
              " 'fixed': tensor(0.0007),\n",
              " 'flamel': tensor(0.0007),\n",
              " 'flames': tensor(0.0007),\n",
              " 'flash': tensor(0.0005),\n",
              " 'flat': tensor(0.0006),\n",
              " 'flavor': tensor(0.0006),\n",
              " 'flew': tensor(0.0006),\n",
              " 'flint': tensor(0.0007),\n",
              " 'flitwick': tensor(0.0006),\n",
              " 'floating': tensor(0.0008),\n",
              " 'floor': tensor(0.0006),\n",
              " 'fluffy': tensor(0.0006),\n",
              " 'flute': tensor(0.0007),\n",
              " 'fly': tensor(0.0007),\n",
              " 'flying': tensor(0.0006),\n",
              " 'follow': tensor(0.0006),\n",
              " 'followed': tensor(0.0007),\n",
              " 'following': tensor(0.0008),\n",
              " 'food': tensor(0.0006),\n",
              " 'foot': tensor(0.0007),\n",
              " 'footsteps': tensor(0.0006),\n",
              " 'for': tensor(0.0007),\n",
              " 'forbidden': tensor(0.0006),\n",
              " 'force': tensor(0.0007),\n",
              " 'forehead': tensor(0.0007),\n",
              " 'forest': tensor(0.0007),\n",
              " 'forget': tensor(0.0005),\n",
              " 'forgotten': tensor(0.0006),\n",
              " 'forward': tensor(0.0007),\n",
              " 'found': tensor(0.0005),\n",
              " 'four': tensor(0.0006),\n",
              " 'fred': tensor(0.0006),\n",
              " 'free': tensor(0.0006),\n",
              " 'friend': tensor(0.0007),\n",
              " 'friends': tensor(0.0007),\n",
              " 'frog': tensor(0.0008),\n",
              " 'frogs': tensor(0.0006),\n",
              " 'from': tensor(0.0007),\n",
              " 'front': tensor(0.0006),\n",
              " 'full': tensor(0.0007),\n",
              " 'fun': tensor(0.0006),\n",
              " 'funny': tensor(0.0007),\n",
              " 'furious': tensor(0.0007),\n",
              " 'furiously': tensor(0.0006),\n",
              " 'game': tensor(0.0007),\n",
              " 'garden': tensor(0.0007),\n",
              " 'gasped': tensor(0.0006),\n",
              " 'gave': tensor(0.0007),\n",
              " 'gently': tensor(0.0007),\n",
              " 'george': tensor(0.0006),\n",
              " 'get': tensor(0.0006),\n",
              " 'gets': tensor(0.0006),\n",
              " 'gettin': tensor(0.0006),\n",
              " 'getting': tensor(0.0007),\n",
              " 'ghost': tensor(0.0007),\n",
              " 'ghosts': tensor(0.0007),\n",
              " 'giant': tensor(0.0007),\n",
              " 'girl': tensor(0.0008),\n",
              " 'girls': tensor(0.0007),\n",
              " 'give': tensor(0.0007),\n",
              " 'given': tensor(0.0006),\n",
              " 'giving': tensor(0.0007),\n",
              " 'glad': tensor(0.0007),\n",
              " 'glass': tensor(0.0006),\n",
              " 'glasses': tensor(0.0007),\n",
              " 'go': tensor(0.0006),\n",
              " 'goal': tensor(0.0007),\n",
              " 'goblin': tensor(0.0007),\n",
              " 'goblins': tensor(0.0007),\n",
              " 'goes': tensor(0.0008),\n",
              " 'going': tensor(0.0006),\n",
              " 'gold': tensor(0.0007),\n",
              " 'golden': tensor(0.0006),\n",
              " 'gone': tensor(0.0007),\n",
              " 'good': tensor(0.0006),\n",
              " 'goodbye': tensor(0.0006),\n",
              " 'got': tensor(0.0005),\n",
              " 'gotta': tensor(0.0005),\n",
              " 'gotten': tensor(0.0006),\n",
              " 'goyle': tensor(0.0007),\n",
              " 'grab': tensor(0.0006),\n",
              " 'grabbed': tensor(0.0006),\n",
              " 'granger': tensor(0.0007),\n",
              " 'grass': tensor(0.0006),\n",
              " 'gray': tensor(0.0005),\n",
              " 'great': tensor(0.0007),\n",
              " 'green': tensor(0.0008),\n",
              " 'grin': tensor(0.0006),\n",
              " 'gringotts': tensor(0.0006),\n",
              " 'griphook': tensor(0.0007),\n",
              " 'ground': tensor(0.0008),\n",
              " 'grounds': tensor(0.0007),\n",
              " 'growled': tensor(0.0006),\n",
              " 'grunted': tensor(0.0007),\n",
              " 'gryffindor': tensor(0.0006),\n",
              " 'gryffindors': tensor(0.0006),\n",
              " 'guard': tensor(0.0006),\n",
              " 'guarding': tensor(0.0006),\n",
              " 'h': tensor(0.0006),\n",
              " 'had': tensor(0.0007),\n",
              " 'hadnt': tensor(0.0006),\n",
              " 'hagrid': tensor(0.0007),\n",
              " 'hagrids': tensor(0.0007),\n",
              " 'hair': tensor(0.0007),\n",
              " 'half': tensor(0.0005),\n",
              " 'halfway': tensor(0.0007),\n",
              " 'hall': tensor(0.0007),\n",
              " 'halloween': tensor(0.0006),\n",
              " 'hand': tensor(0.0008),\n",
              " 'handed': tensor(0.0007),\n",
              " 'handle': tensor(0.0008),\n",
              " 'hands': tensor(0.0007),\n",
              " 'hang': tensor(0.0007),\n",
              " 'hanging': tensor(0.0006),\n",
              " 'happen': tensor(0.0007),\n",
              " 'happened': tensor(0.0006),\n",
              " 'happy': tensor(0.0006),\n",
              " 'hard': tensor(0.0007),\n",
              " 'harder': tensor(0.0007),\n",
              " 'hardly': tensor(0.0007),\n",
              " 'harry': tensor(0.0018),\n",
              " 'harrys': tensor(0.0007),\n",
              " 'has': tensor(0.0007),\n",
              " 'hasnt': tensor(0.0007),\n",
              " 'hat': tensor(0.0006),\n",
              " 'hate': tensor(0.0007),\n",
              " 'hated': tensor(0.0006),\n",
              " 'have': tensor(0.0006),\n",
              " 'havent': tensor(0.0006),\n",
              " 'having': tensor(0.0006),\n",
              " 'he': tensor(0.0006),\n",
              " 'head': tensor(0.0008),\n",
              " 'headless': tensor(0.0008),\n",
              " 'heads': tensor(0.0007),\n",
              " 'hear': tensor(0.0007),\n",
              " 'heard': tensor(0.0007),\n",
              " 'heart': tensor(0.0007),\n",
              " 'heavy': tensor(0.0007),\n",
              " 'hed': tensor(0.0007),\n",
              " 'hedwig': tensor(0.0006),\n",
              " 'held': tensor(0.0007),\n",
              " 'hell': tensor(0.0008),\n",
              " 'help': tensor(0.0007),\n",
              " 'her': tensor(0.0007),\n",
              " 'here': tensor(0.0006),\n",
              " 'hermione': tensor(0.0008),\n",
              " 'hermiones': tensor(0.0008),\n",
              " 'herself': tensor(0.0007),\n",
              " 'hes': tensor(0.0008),\n",
              " 'hidden': tensor(0.0007),\n",
              " 'hide': tensor(0.0007),\n",
              " 'hiding': tensor(0.0005),\n",
              " 'high': tensor(0.0007),\n",
              " 'higher': tensor(0.0007),\n",
              " 'him': tensor(0.0007),\n",
              " 'himself': tensor(0.0008),\n",
              " 'his': tensor(0.0007),\n",
              " 'hissed': tensor(0.0007),\n",
              " 'history': tensor(0.0007),\n",
              " 'hit': tensor(0.0007),\n",
              " 'hogwarts': tensor(0.0007),\n",
              " 'hold': tensor(0.0007),\n",
              " 'holding': tensor(0.0006),\n",
              " 'hole': tensor(0.0006),\n",
              " 'holidays': tensor(0.0007),\n",
              " 'home': tensor(0.0007),\n",
              " 'homework': tensor(0.0007),\n",
              " 'honestly': tensor(0.0006),\n",
              " 'hooch': tensor(0.0006),\n",
              " 'hoops': tensor(0.0006),\n",
              " 'hope': tensor(0.0006),\n",
              " 'hoping': tensor(0.0006),\n",
              " 'horrible': tensor(0.0007),\n",
              " 'horror': tensor(0.0006),\n",
              " 'hospital': tensor(0.0007),\n",
              " 'hot': tensor(0.0007),\n",
              " 'hour': tensor(0.0008),\n",
              " 'hours': tensor(0.0006),\n",
              " 'house': tensor(0.0007),\n",
              " 'houses': tensor(0.0007),\n",
              " 'how': tensor(0.0006),\n",
              " 'however': tensor(0.0006),\n",
              " 'howling': tensor(0.0007),\n",
              " 'hufflepuff': tensor(0.0005),\n",
              " 'huge': tensor(0.0007),\n",
              " 'human': tensor(0.0005),\n",
              " 'hundred': tensor(0.0005),\n",
              " 'hundreds': tensor(0.0006),\n",
              " 'hung': tensor(0.0007),\n",
              " 'hungry': tensor(0.0007),\n",
              " 'hurried': tensor(0.0006),\n",
              " 'hurry': tensor(0.0006),\n",
              " 'hurrying': tensor(0.0007),\n",
              " 'hurt': tensor(0.0006),\n",
              " 'hut': tensor(0.0007),\n",
              " 'i': tensor(0.0007),\n",
              " 'ice': tensor(0.0007),\n",
              " 'id': tensor(0.0007),\n",
              " 'idea': tensor(0.0008),\n",
              " 'if': tensor(0.0007),\n",
              " 'ignored': tensor(0.0008),\n",
              " 'ill': tensor(0.0006),\n",
              " 'im': tensor(0.0007),\n",
              " 'imagine': tensor(0.0007),\n",
              " 'important': tensor(0.0007),\n",
              " 'in': tensor(0.0006),\n",
              " 'inches': tensor(0.0006),\n",
              " 'indeed': tensor(0.0007),\n",
              " 'inside': tensor(0.0007),\n",
              " 'instead': tensor(0.0007),\n",
              " 'interested': tensor(0.0006),\n",
              " 'interesting': tensor(0.0007),\n",
              " 'into': tensor(0.0006),\n",
              " 'invisibility': tensor(0.0007),\n",
              " 'invisible': tensor(0.0006),\n",
              " 'is': tensor(0.0007),\n",
              " 'isnt': tensor(0.0007),\n",
              " 'it': tensor(0.0007),\n",
              " 'itll': tensor(0.0008),\n",
              " 'its': tensor(0.0008),\n",
              " 'itself': tensor(0.0006),\n",
              " 'ive': tensor(0.0007),\n",
              " 'jerked': tensor(0.0007),\n",
              " 'job': tensor(0.0008),\n",
              " 'join': tensor(0.0007),\n",
              " 'joined': tensor(0.0007),\n",
              " 'joke': tensor(0.0007),\n",
              " 'jordan': tensor(0.0007),\n",
              " 'jump': tensor(0.0007),\n",
              " 'jumped': tensor(0.0007),\n",
              " 'jus': tensor(0.0006),\n",
              " 'just': tensor(0.0007),\n",
              " 'keep': tensor(0.0008),\n",
              " 'keeper': tensor(0.0007),\n",
              " 'keeping': tensor(0.0008),\n",
              " 'kept': tensor(0.0006),\n",
              " 'key': tensor(0.0007),\n",
              " 'keys': tensor(0.0007),\n",
              " 'kicked': tensor(0.0007),\n",
              " 'kill': tensor(0.0007),\n",
              " 'killed': tensor(0.0005),\n",
              " 'kind': tensor(0.0007),\n",
              " 'kings': tensor(0.0007),\n",
              " 'kitchen': tensor(0.0006),\n",
              " 'knees': tensor(0.0007),\n",
              " 'knew': tensor(0.0007),\n",
              " 'knight': tensor(0.0007),\n",
              " 'knock': tensor(0.0007),\n",
              " 'knocked': tensor(0.0007),\n",
              " 'knocking': tensor(0.0007),\n",
              " 'know': tensor(0.0007),\n",
              " 'knowing': tensor(0.0006),\n",
              " 'known': tensor(0.0007),\n",
              " 'knows': tensor(0.0006),\n",
              " 'knuts': tensor(0.0007),\n",
              " 'lady': tensor(0.0006),\n",
              " 'lake': tensor(0.0007),\n",
              " 'lamp': tensor(0.0007),\n",
              " 'landed': tensor(0.0006),\n",
              " 'large': tensor(0.0007),\n",
              " 'last': tensor(0.0007),\n",
              " 'late': tensor(0.0007),\n",
              " 'later': tensor(0.0006),\n",
              " 'laugh': tensor(0.0006),\n",
              " 'laughed': tensor(0.0007),\n",
              " 'laughing': tensor(0.0007),\n",
              " 'laughter': tensor(0.0007),\n",
              " 'lay': tensor(0.0007),\n",
              " 'lead': tensor(0.0007),\n",
              " 'leading': tensor(0.0007),\n",
              " 'leaky': tensor(0.0007),\n",
              " 'leaned': tensor(0.0008),\n",
              " 'leapt': tensor(0.0006),\n",
              " 'learn': tensor(0.0007),\n",
              " 'learned': tensor(0.0006),\n",
              " 'least': tensor(0.0006),\n",
              " 'leave': tensor(0.0007),\n",
              " 'leaves': tensor(0.0007),\n",
              " 'leaving': tensor(0.0006),\n",
              " 'led': tensor(0.0006),\n",
              " 'lee': tensor(0.0007),\n",
              " 'left': tensor(0.0006),\n",
              " 'leg': tensor(0.0007),\n",
              " 'legs': tensor(0.0007),\n",
              " 'lemon': tensor(0.0007),\n",
              " 'less': tensor(0.0008),\n",
              " 'lesson': tensor(0.0007),\n",
              " 'lessons': tensor(0.0006),\n",
              " 'let': tensor(0.0007),\n",
              " 'lets': tensor(0.0007),\n",
              " 'letter': tensor(0.0007),\n",
              " 'letters': tensor(0.0006),\n",
              " 'library': tensor(0.0007),\n",
              " 'lie': tensor(0.0007),\n",
              " 'life': tensor(0.0006),\n",
              " 'light': tensor(0.0007),\n",
              " 'lightning': tensor(0.0007),\n",
              " 'like': tensor(0.0007),\n",
              " 'liked': tensor(0.0006),\n",
              " 'lily': tensor(0.0007),\n",
              " 'line': tensor(0.0006),\n",
              " 'lips': tensor(0.0006),\n",
              " 'list': tensor(0.0006),\n",
              " 'listen': tensor(0.0007),\n",
              " 'listening': tensor(0.0007),\n",
              " 'lit': tensor(0.0007),\n",
              " 'little': tensor(0.0005),\n",
              " 'live': tensor(0.0007),\n",
              " 'lived': tensor(0.0007),\n",
              " 'living': tensor(0.0007),\n",
              " 'loads': tensor(0.0008),\n",
              " 'lock': tensor(0.0007),\n",
              " 'locked': tensor(0.0007),\n",
              " 'london': tensor(0.0006),\n",
              " 'long': tensor(0.0006),\n",
              " 'longbottom': tensor(0.0007),\n",
              " 'look': tensor(0.0007),\n",
              " 'looked': tensor(0.0007),\n",
              " 'looking': tensor(0.0007),\n",
              " 'looks': tensor(0.0007),\n",
              " 'lose': tensor(0.0007),\n",
              " 'losing': tensor(0.0007),\n",
              " 'lost': tensor(0.0007),\n",
              " 'lot': tensor(0.0006),\n",
              " 'lots': tensor(0.0008),\n",
              " 'loud': tensor(0.0006),\n",
              " 'loudly': tensor(0.0006),\n",
              " 'low': tensor(0.0007),\n",
              " 'luck': tensor(0.0006),\n",
              " 'lucky': tensor(0.0007),\n",
              " 'lumpy': tensor(0.0005),\n",
              " 'lurking': tensor(0.0008),\n",
              " 'lying': tensor(0.0007),\n",
              " 'mad': tensor(0.0007),\n",
              " 'madam': tensor(0.0005),\n",
              " 'made': tensor(0.0007),\n",
              " 'magic': tensor(0.0006),\n",
              " 'magical': tensor(0.0006),\n",
              " 'mail': tensor(0.0006),\n",
              " 'make': tensor(0.0007),\n",
              " 'making': tensor(0.0007),\n",
              " 'malfoy': tensor(0.0007),\n",
              " 'malfoys': tensor(0.0006),\n",
              " 'man': tensor(0.0006),\n",
              " 'managed': tensor(0.0006),\n",
              " 'many': tensor(0.0006),\n",
              " 'marble': tensor(0.0008),\n",
              " 'marched': tensor(0.0006),\n",
              " 'match': tensor(0.0006),\n",
              " 'matter': tensor(0.0007),\n",
              " 'may': tensor(0.0007),\n",
              " 'maybe': tensor(0.0007),\n",
              " 'mcgonagall': tensor(0.0007),\n",
              " 'mcgonagalls': tensor(0.0006),\n",
              " 'me': tensor(0.0008),\n",
              " 'mean': tensor(0.0006),\n",
              " 'means': tensor(0.0007),\n",
              " 'meant': tensor(0.0006),\n",
              " 'meet': tensor(0.0007),\n",
              " 'mention': tensor(0.0005),\n",
              " 'met': tensor(0.0007),\n",
              " 'midair': tensor(0.0006),\n",
              " 'middle': tensor(0.0007),\n",
              " 'midnight': tensor(0.0006),\n",
              " 'might': tensor(0.0007),\n",
              " 'mind': tensor(0.0007),\n",
              " 'ministry': tensor(0.0008),\n",
              " 'minute': tensor(0.0006),\n",
              " 'minutes': tensor(0.0006),\n",
              " 'mirror': tensor(0.0006),\n",
              " 'miss': tensor(0.0007),\n",
              " 'mistake': tensor(0.0008),\n",
              " 'moaned': tensor(0.0006),\n",
              " 'mom': tensor(0.0007),\n",
              " 'moment': tensor(0.0008),\n",
              " 'money': tensor(0.0008),\n",
              " 'moonlight': tensor(0.0007),\n",
              " 'more': tensor(0.0007),\n",
              " 'morning': tensor(0.0006),\n",
              " 'most': tensor(0.0006),\n",
              " 'mother': tensor(0.0007),\n",
              " 'mothers': tensor(0.0006),\n",
              " 'motorcycle': tensor(0.0006),\n",
              " 'mountain': tensor(0.0008),\n",
              " 'mouth': tensor(0.0007),\n",
              " 'move': tensor(0.0007),\n",
              " 'moved': tensor(0.0007),\n",
              " 'moving': tensor(0.0006),\n",
              " 'mr': tensor(0.0006),\n",
              " 'mrs': tensor(0.0008),\n",
              " 'much': tensor(0.0007),\n",
              " 'muggle': tensor(0.0006),\n",
              " 'muggles': tensor(0.0006),\n",
              " 'murmured': tensor(0.0007),\n",
              " 'must': tensor(0.0006),\n",
              " 'mustache': tensor(0.0006),\n",
              " 'mustve': tensor(0.0006),\n",
              " 'muttered': tensor(0.0007),\n",
              " 'muttering': tensor(0.0007),\n",
              " 'my': tensor(0.0007),\n",
              " 'myself': tensor(0.0007),\n",
              " 'mysterious': tensor(0.0007),\n",
              " 'nah': tensor(0.0006),\n",
              " 'name': tensor(0.0006),\n",
              " 'names': tensor(0.0006),\n",
              " 'narrow': tensor(0.0006),\n",
              " 'nasty': tensor(0.0006),\n",
              " 'near': tensor(0.0006),\n",
              " 'nearer': tensor(0.0006),\n",
              " 'nearest': tensor(0.0007),\n",
              " 'nearly': tensor(0.0007),\n",
              " 'neck': tensor(0.0006),\n",
              " 'need': tensor(0.0006),\n",
              " 'needed': tensor(0.0008),\n",
              " 'needs': tensor(0.0007),\n",
              " 'neither': tensor(0.0006),\n",
              " 'nervous': tensor(0.0006),\n",
              " 'nervously': tensor(0.0007),\n",
              " 'never': tensor(0.0007),\n",
              " 'neville': tensor(0.0007),\n",
              " 'nevilles': tensor(0.0006),\n",
              " 'new': tensor(0.0007),\n",
              " 'news': tensor(0.0006),\n",
              " 'newspaper': tensor(0.0007),\n",
              " 'next': tensor(0.0007),\n",
              " 'nice': tensor(0.0007),\n",
              " 'nicolas': tensor(0.0006),\n",
              " 'night': tensor(0.0006),\n",
              " 'nimbus': tensor(0.0007),\n",
              " 'nine': tensor(0.0007),\n",
              " 'no': tensor(0.0007),\n",
              " 'nobody': tensor(0.0007),\n",
              " 'nodded': tensor(0.0007),\n",
              " 'noise': tensor(0.0006),\n",
              " 'none': tensor(0.0007),\n",
              " 'nor': tensor(0.0006),\n",
              " 'norbert': tensor(0.0006),\n",
              " 'normal': tensor(0.0007),\n",
              " 'norris': tensor(0.0007),\n",
              " 'nose': tensor(0.0007),\n",
              " 'noses': tensor(0.0006),\n",
              " 'nostrils': tensor(0.0007),\n",
              " 'not': tensor(0.0007),\n",
              " 'note': tensor(0.0006),\n",
              " 'notes': tensor(0.0008),\n",
              " 'nothin': tensor(0.0007),\n",
              " 'nothing': tensor(0.0006),\n",
              " 'notice': tensor(0.0007),\n",
              " 'noticed': tensor(0.0006),\n",
              " 'noticing': tensor(0.0006),\n",
              " 'now': tensor(0.0006),\n",
              " 'number': tensor(0.0008),\n",
              " 'o': tensor(0.0006),\n",
              " 'obviously': tensor(0.0007),\n",
              " 'oclock': tensor(0.0007),\n",
              " 'odd': tensor(0.0007),\n",
              " 'of': tensor(0.0006),\n",
              " 'off': tensor(0.0007),\n",
              " 'often': tensor(0.0006),\n",
              " 'oh': tensor(0.0006),\n",
              " 'old': tensor(0.0006),\n",
              " 'older': tensor(0.0007),\n",
              " 'ollivander': tensor(0.0006),\n",
              " 'on': tensor(0.0006),\n",
              " 'once': tensor(0.0006),\n",
              " 'one': tensor(0.0005),\n",
              " 'ones': tensor(0.0008),\n",
              " 'only': tensor(0.0007),\n",
              " 'onto': tensor(0.0007),\n",
              " 'open': tensor(0.0007),\n",
              " 'opened': tensor(0.0007),\n",
              " 'opposite': tensor(0.0006),\n",
              " 'or': tensor(0.0006),\n",
              " 'ordinary': tensor(0.0006),\n",
              " 'other': tensor(0.0006),\n",
              " 'others': tensor(0.0007),\n",
              " 'our': tensor(0.0006),\n",
              " 'out': tensor(0.0006),\n",
              " 'outside': tensor(0.0006),\n",
              " 'outta': tensor(0.0007),\n",
              " 'over': tensor(0.0007),\n",
              " 'overhead': tensor(0.0006),\n",
              " 'owl': tensor(0.0006),\n",
              " 'owls': tensor(0.0006),\n",
              " 'own': tensor(0.0006),\n",
              " 'pack': tensor(0.0007),\n",
              " 'package': tensor(0.0006),\n",
              " 'packed': tensor(0.0006),\n",
              " 'pain': tensor(0.0007),\n",
              " 'pair': tensor(0.0006),\n",
              " 'pale': tensor(0.0007),\n",
              " 'panted': tensor(0.0006),\n",
              " 'paper': tensor(0.0007),\n",
              " 'parcel': tensor(0.0006),\n",
              " 'parchment': tensor(0.0006),\n",
              " 'parents': tensor(0.0007),\n",
              " 'particularly': tensor(0.0007),\n",
              " 'passageway': tensor(0.0007),\n",
              " 'passed': tensor(0.0006),\n",
              " 'passing': tensor(0.0007),\n",
              " 'past': tensor(0.0005),\n",
              " 'path': tensor(0.0007),\n",
              " 'patil': tensor(0.0007),\n",
              " 'peered': tensor(0.0007),\n",
              " 'peering': tensor(0.0006),\n",
              " 'peeves': tensor(0.0007),\n",
              " 'people': tensor(0.0007),\n",
              " 'percy': tensor(0.0006),\n",
              " 'perfect': tensor(0.0007),\n",
              " 'perhaps': tensor(0.0006),\n",
              " 'person': tensor(0.0007),\n",
              " 'petunia': tensor(0.0007),\n",
              " 'picked': tensor(0.0007),\n",
              " 'piece': tensor(0.0007),\n",
              " 'pieces': tensor(0.0008),\n",
              " 'piers': tensor(0.0007),\n",
              " 'pig': tensor(0.0006),\n",
              " 'pile': tensor(0.0007),\n",
              " 'piled': tensor(0.0006),\n",
              " 'pink': tensor(0.0007),\n",
              " 'pinned': tensor(0.0006),\n",
              " 'place': tensor(0.0007),\n",
              " 'planets': tensor(0.0006),\n",
              " 'plant': tensor(0.0006),\n",
              " 'plates': tensor(0.0007),\n",
              " 'platform': tensor(0.0007),\n",
              " 'platforms': tensor(0.0006),\n",
              " 'play': tensor(0.0007),\n",
              " 'players': tensor(0.0007),\n",
              " 'playing': tensor(0.0007),\n",
              " 'please': tensor(0.0006),\n",
              " 'pleased': tensor(0.0007),\n",
              " 'pocket': tensor(0.0007),\n",
              " 'pockets': tensor(0.0006),\n",
              " 'point': tensor(0.0008),\n",
              " 'pointed': tensor(0.0006),\n",
              " 'pointing': tensor(0.0006),\n",
              " 'points': tensor(0.0006),\n",
              " 'pomfrey': tensor(0.0006),\n",
              " 'poor': tensor(0.0006),\n",
              " 'portrait': tensor(0.0006),\n",
              " 'possession': tensor(0.0007),\n",
              " 'possible': tensor(0.0006),\n",
              " 'posts': tensor(0.0007),\n",
              " 'potion': tensor(0.0006),\n",
              " 'potions': tensor(0.0007),\n",
              " 'potter': tensor(0.0007),\n",
              " 'potters': tensor(0.0007),\n",
              " 'power': tensor(0.0007),\n",
              " 'powerful': tensor(0.0005),\n",
              " 'practice': tensor(0.0006),\n",
              " 'prefect': tensor(0.0007),\n",
              " 'prefects': tensor(0.0006),\n",
              " 'presents': tensor(0.0006),\n",
              " 'pressed': tensor(0.0006),\n",
              " 'privet': tensor(0.0006),\n",
              " 'probably': tensor(0.0007),\n",
              " 'professor': tensor(0.0007),\n",
              " 'properly': tensor(0.0007),\n",
              " 'proud': tensor(0.0006),\n",
              " 'pull': tensor(0.0008),\n",
              " 'pulled': tensor(0.0006),\n",
              " 'pulling': tensor(0.0006),\n",
              " 'purple': tensor(0.0006),\n",
              " 'pushed': tensor(0.0006),\n",
              " 'put': tensor(0.0006),\n",
              " 'quaffle': tensor(0.0007),\n",
              " 'question': tensor(0.0007),\n",
              " 'questions': tensor(0.0007),\n",
              " 'quick': tensor(0.0007),\n",
              " 'quickly': tensor(0.0007),\n",
              " 'quidditch': tensor(0.0007),\n",
              " 'quiet': tensor(0.0008),\n",
              " 'quietly': tensor(0.0008),\n",
              " 'quills': tensor(0.0007),\n",
              " 'quirrell': tensor(0.0008),\n",
              " 'quirrells': tensor(0.0007),\n",
              " 'quite': tensor(0.0007),\n",
              " 'racing': tensor(0.0007),\n",
              " 'raised': tensor(0.0008),\n",
              " 'ran': tensor(0.0006),\n",
              " 'rang': tensor(0.0007),\n",
              " 'rat': tensor(0.0006),\n",
              " 'rather': tensor(0.0007),\n",
              " 'ravenclaw': tensor(0.0007),\n",
              " 'reached': tensor(0.0007),\n",
              " 'read': tensor(0.0007),\n",
              " 'ready': tensor(0.0006),\n",
              " 'real': tensor(0.0006),\n",
              " 'realize': tensor(0.0008),\n",
              " 'realized': tensor(0.0007),\n",
              " 'really': tensor(0.0007),\n",
              " 'reason': tensor(0.0006),\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from math import exp\n",
        "word_exp_dict = {}\n",
        "for word, dot_value in word_dot_dict.items():\n",
        "  exp_value = torch.exp(dot_value)\n",
        "  word_exp_dict[word] = exp_value\n",
        "\n",
        "sum_exp = sum([value for value in word_exp_dict.values()])\n",
        "word_prob_dict = {}\n",
        "for word, exp_value in word_exp_dict.items():\n",
        "  word_prob_dict[word] = exp_value / sum_exp\n",
        "\n",
        "word_prob_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SpXH7RxSbwUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a10116-dab8-42b2-a4ed-0032e73ca549"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0018)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Get P(potter|harry)\n",
        "word_prob_dict['harry']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKxz9SJhSuhy"
      },
      "source": [
        "## 13. Efficient Matrix Operations\n",
        "![img](https://mkang32.github.io/images/python/khan_academy_matrix_product.png)\n",
        "\n",
        "Instead of calculating dot products one by one, we can use matrix multiplication for efficiency:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "harry, potter\n",
        "center_word_mat = torch.stack([harry, potter])\n",
        "center_word_mat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LewMQbHtBolH",
        "outputId": "37495b5d-e486-4bf5-d6b6-e9f4e3d59508"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HCFajiDkb44W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918247eb-21fb-414a-d112-ccd8ef26d557"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1506, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# get dot product result for every word in the vocabulary\n",
        "harry.shape\n",
        "# first, make vector_of_harry into matrix format\n",
        "harry_mat = harry.unsqueeze(0)\n",
        "word_vectors.shape\n",
        "# do matrix multiplication\n",
        "dot_by_mat = torch.mm(center_word_mat, word_vectors.T)\n",
        "dot_by_mat = dot_by_mat.T\n",
        "dot_by_mat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03qx3olEkzqe"
      },
      "source": [
        "Let's verify that our matrix multiplication gives the same result as individual dot products:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wGpJCtJQkzqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4090c96c-6596-46b8-b2be-2c4497450521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0057,  0.9501]), tensor(-0.0057))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dot_by_mat[word2idx['potter']], word_dot_dict['potter']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2tW_Q6kkzqe"
      },
      "source": [
        "Now let's implement the complete softmax calculation using matrix operations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5USdps5CfKzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69da829c-e287-40a7-8ebf-a1e7ec850c7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1506, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# convert dot product result into exponential\n",
        "mat_exp = torch.exp(dot_by_mat)\n",
        "mat_exp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WNq0gqz0fntB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3663dd4-09f8-49fc-8e96-8b2807928060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8485],\n",
              "        [1.9712],\n",
              "        [2.1687],\n",
              "        ...,\n",
              "        [1.9100],\n",
              "        [1.8822],\n",
              "        [1.9644]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# get the sum of exponential\n",
        "sum(mat_exp)\n",
        "sum_of_mat_exp = torch.sum(mat_exp, dim=1, keepdim=True)\n",
        "sum_of_mat_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ruV4_myDgLvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd8499f-223e-4970-cf77-749327bcd2ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# divide exponential value with sum\n",
        "prob = mat_exp / sum(mat_exp)\n",
        "prob.sum(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ228pigkzqf"
      },
      "source": [
        "## 14. Creating a Probability Function\n",
        "\n",
        "Let's create a function to calculate probabilities efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EF4gutuEgntj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5aae57-6e4f-406d-aa1c-08378e27c916"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0006, 0.0006],\n",
              "        [0.0007, 0.0007],\n",
              "        [0.0007, 0.0007],\n",
              "        ...,\n",
              "        [0.0006, 0.0006],\n",
              "        [0.0006, 0.0007],\n",
              "        [0.0007, 0.0006]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "def get_probs(query_vectors, entire_vectors):\n",
        "  dot_by_mat = torch.mm(query_vectors, entire_vectors.T)\n",
        "  dot_by_mat = dot_by_mat.T\n",
        "  mat_exp = torch.exp(dot_by_mat)\n",
        "  sum_of_mat_exp = torch.sum(mat_exp, dim=0)\n",
        "  prob = mat_exp / sum_of_mat_exp\n",
        "  return prob\n",
        "\n",
        "get_probs(center_word_mat, word_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyVcT_6wkzqf"
      },
      "source": [
        "## 15. Preparing for Training\n",
        "\n",
        "Before training our Word2Vec model, we need to split our dataset into training and testing sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3gjCSY3DoaFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7764a7d-1e0d-45db-924b-176d48cbc51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226846\n"
          ]
        }
      ],
      "source": [
        "# Now we can train the word2vec\n",
        "import random,\n",
        "\n",
        "# Let's think about training pairs\n",
        "index_pairs # this is our dataset. It's list of list of two integer\n",
        "print(len(index_pairs))\n",
        "# two integer means a pair of neighboring words\n",
        "\n",
        "# Training set and Test set\n",
        "# To validate that our model can solve 'unseen' problems\n",
        "# So we have to split the dataset before training.\n",
        "\n",
        "# To randomly split the dataset, we will first shuffle the dataset\n",
        "\n",
        "random.shuffle(index_pairs) # this will shuffle the list items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = index_pairs[:200000]\n",
        "test_set = index_pairs[200000:]"
      ],
      "metadata": {
        "id": "NPG3PcRDEj8k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TC0QF3NZp9Rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09146859-620a-43aa-b5af-93c717b5f7cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 26846)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_set), len(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7m_ZB-Vkzqf"
      },
      "source": [
        "## 16. Training the Word2Vec Model\n",
        "\n",
        "Now we'll train our Word2Vec model using batched gradient descent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JpUM3aiiqG8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ac4eb0-7655-496c-91e4-0d4a74d1e0fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1506, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# making batch from train_set\n",
        "# Batch is a set of training samples, that are calculated together\n",
        "# And also we update the model after one single batch\n",
        "\n",
        "word_vectors.requires_grad = True\n",
        "batch = train_set[:20]\n",
        "batch\n",
        "center_words = [x[0] for x in batch]\n",
        "context_words = [x[1] for x in batch]\n",
        "\n",
        "center_words_vectors = word_vectors[center_words]\n",
        "prob = get_probs(center_words_vectors, word_vectors)\n",
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "def update_word_vectors(center_words, context_words, word_vectors, learning_rate=0.01) :\n",
        "  center_words_vectors = word_vectors[center_words]\n",
        "  prob=get_probs(center_words_vectors,entire_vectors=word_vectors)\n",
        "  # print(context_words)\n",
        "  # idx=0\n",
        "  # for idx in range(len(context_words)):\n",
        "  #   prob_of_correct_context_word_for_given_idx = prob[context_words[idx],idx]\n",
        "  #   #print(prob_of_correct_context_word_for_given_idx)\n",
        "  prob_of_correct_context_word = prob[context_words, torch.arange(len(context_words))]\n",
        "  negative_log_likelihood = -torch.log(prob_of_correct_context_word)\n",
        "  loss=negative_log_likelihood.mean()\n",
        "  # backprop the loss\n",
        "  loss.backward()\n",
        "  # word_vectors.grad\n",
        "  word_vectors.data = word_vectors.data - word_vectors.grad * learning_rate\n",
        "  word_vectors.grad = None\n",
        "  word_vectors.data.grad = None\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "ibvsuAMbqOH9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_record=[]\n",
        "for i in range(100):\n",
        "\n",
        "  loss = update_word_vectors(center_words,context_words,word_vectors, learning_rate=0.1)\n",
        "  loss_record.append(loss)\n",
        "plt.plot(loss_record)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "JtNkZgojx1Ma",
        "outputId": "cacceb98-cc03-4983-ad19-b9bfdefade09"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28415900468826294"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# batch = train_set[:20]\n",
        "# batch\n",
        "# center_words = [x[0] for x in batch]\n",
        "# context_words = [x[1] for x in batch]\n",
        "batch_size=100\n",
        "batch_start_idx = 0\n",
        "batch_end_idx=batch_start_idx+batch_size\n",
        "\n",
        "loss_record = []\n",
        "n_epoch = 3\n",
        "\n",
        "for epoch in tqdm(range(n_epoch)):\n",
        "  for batch_start_idx in range(0, len(train_set), batch_size):\n",
        "    batch=train_set[batch_start_idx:batch_start_idx+batch_size]\n",
        "    center_words = [x[0] for x in batch]\n",
        "    context_words = [x[1] for x in batch]\n",
        "    loss = update_word_vectors(center_words,context_words,word_vectors, learning_rate=0.1)\n",
        "    loss_record.append(loss)"
      ],
      "metadata": {
        "id": "0C-FOgevzHN_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e98955d003f34b3ebfa17f860b5ea9a5",
            "4501bdcef55c407bb166c9d82dd94196",
            "7d0c539e51564b5fa37d9866c8a204f6",
            "7505a3e7c55b468caf770b8c54220b23",
            "e50e0d910e2146b5858c570ae3cfebae",
            "5b8c10b6f3ff456699f3269bcbf8dbc0",
            "0e4b48964527478198877e9b2b155fc6",
            "51658b45e8e8453584cb810eacc86d72",
            "65dee517a0704b5f8c8b9b8f334aa5d8",
            "df5024da00b3433b8deb4b1ccb45725f",
            "921473500d944fce95d18dfc3353d797"
          ]
        },
        "outputId": "6bb59700-08cc-439c-999e-22d14a1bae20"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e98955d003f34b3ebfa17f860b5ea9a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, test_set):\n",
        "    loss = update_word_vectors(center_words,context_words,word_vectors, learning_rate=0.1)\n",
        "    loss_record.append(loss)\n",
        ""
      ],
      "metadata": {
        "id": "RtMbsAo85iGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "NxrHJgpA4hg3",
        "outputId": "2d97b85c-05e0-4e4e-e687-d55885e706d6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0a68e880d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuUAzGoukzqf"
      },
      "source": [
        "## 17. Evaluating the Training\n",
        "\n",
        "Let's visualize the training loss to see if our model is learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJHSV8zbyLYu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(loss_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7agT-5NPkzqf"
      },
      "source": [
        "## 18. Testing the Model\n",
        "\n",
        "Now we'll test our model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDP9aR48zdJu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2ZOErd0kzqf"
      },
      "source": [
        "## 19. Exploring Learned Word Relationships\n",
        "\n",
        "Let's explore what our model has learned by finding the words most closely related to \"harry\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YaCDNq_0hFc"
      },
      "outputs": [],
      "source": [
        "# P(potter|harry)?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e98955d003f34b3ebfa17f860b5ea9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4501bdcef55c407bb166c9d82dd94196",
              "IPY_MODEL_7d0c539e51564b5fa37d9866c8a204f6",
              "IPY_MODEL_7505a3e7c55b468caf770b8c54220b23"
            ],
            "layout": "IPY_MODEL_e50e0d910e2146b5858c570ae3cfebae"
          }
        },
        "4501bdcef55c407bb166c9d82dd94196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b8c10b6f3ff456699f3269bcbf8dbc0",
            "placeholder": "​",
            "style": "IPY_MODEL_0e4b48964527478198877e9b2b155fc6",
            "value": "100%"
          }
        },
        "7d0c539e51564b5fa37d9866c8a204f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51658b45e8e8453584cb810eacc86d72",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65dee517a0704b5f8c8b9b8f334aa5d8",
            "value": 3
          }
        },
        "7505a3e7c55b468caf770b8c54220b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df5024da00b3433b8deb4b1ccb45725f",
            "placeholder": "​",
            "style": "IPY_MODEL_921473500d944fce95d18dfc3353d797",
            "value": " 3/3 [00:28&lt;00:00,  9.52s/it]"
          }
        },
        "e50e0d910e2146b5858c570ae3cfebae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8c10b6f3ff456699f3269bcbf8dbc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4b48964527478198877e9b2b155fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51658b45e8e8453584cb810eacc86d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65dee517a0704b5f8c8b9b8f334aa5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df5024da00b3433b8deb4b1ccb45725f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921473500d944fce95d18dfc3353d797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}