{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunmyeonglee/2025-1-NLP/blob/main/3_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8vQzOle74-cJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXbsjcoKIC93"
      },
      "source": [
        "# Language modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y1EwAtYF4-cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0257cbc0-c7cc-4e2e-ee36-cab82b0dd3c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-20 04:40:23--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-20 04:40:23 (10.2 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xbdOy7ia4-cK"
      },
      "outputs": [],
      "source": [
        "def read_txt(txt_path):\n",
        "  with open(txt_path, 'r') as f:\n",
        "    txt_string = f.readlines()\n",
        "  return txt_string\n",
        "\n",
        "txt_string = read_txt('names.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iSIJEvdSN3aO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e02f356-774d-451b-f61c-4cbfb6681dfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "names_list = [x.replace('\\n', '') for x in txt_string]\n",
        "len(names_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUGS4Rf6OFgZ"
      },
      "source": [
        "# N-Gram\n",
        "- Start with bi-gram (2-gram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BUchO_cFOE6O"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# bigram_dict = {}\n",
        "bigram_dict = defaultdict(int) # If key is not in the defaultdict, it automatically assign key and empty value (int=0, list=[])\n",
        "unigram_dict = defaultdict(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53aB-trqviem"
      },
      "source": [
        "# RNN\n",
        "- $h_t = \\tanh(\\textbf{W}_{hh}h_{t-1} + \\textbf{W}_{xh}x_t + b) $\n",
        "  - $\\textbf{W}$: Weight Matrix\n",
        "  - $b$: bias\n",
        "  - $x_t$: input vector of time step $t$\n",
        "  - $h_t$: hidden state (and also output) of time step $t$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "sequence_length = 7\n",
        "input_dim, hidden_dim = 3, 5\n",
        "weight_hh = nn.Linear(hidden_dim, hidden_dim)\n",
        "weight_xh = nn.Linear(input_dim, hidden_dim)\n",
        "h0 = torch.zeros(hidden_dim)\n",
        "x = torch.randn([sequence_length, input_dim])\n",
        "t = 0\n",
        "x_t = x[t]\n",
        "x[t]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxKz76cb6ZLl",
        "outputId": "f69c7403-af84-431f-c1c4-a108d6198743"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0554,  0.1778, -0.2303])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_t = torch.tanh(weight_hh(h0) + weight_xh(x_t))\n",
        "h_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URPjj_-790bm",
        "outputId": "8efb9304-4f50-47dc-efc1-d4f5c8b615ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3031,  0.4942, -0.3826, -0.1671, -0.0307], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_rnn_cell(weight_hh, weight_xh, prev_h, x_t):\n",
        "  return torch.tanh(weight_hh(prev_h) + weight_xh(x_t))\n",
        "\n",
        "output = []\n",
        "prev_h = h0\n",
        "for i in range(len(x)):\n",
        "  print(f'x: {x[i]}')\n",
        "  h = run_rnn_cell(weight_hh, weight_xh, prev_h, x[i])\n",
        "  prev_h = h\n",
        "  print(f'h: {h}')\n",
        "  output.append(h)\n",
        "\n",
        "output = torch.stack(output)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLTNGxj5-tZT",
        "outputId": "19d63621-833a-41b6-d08a-a1b2fb1cab23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([ 1.0554,  0.1778, -0.2303])\n",
            "h: tensor([-0.3031,  0.4942, -0.3826, -0.1671, -0.0307], grad_fn=<TanhBackward0>)\n",
            "x: tensor([-0.3918,  0.5433,  0.3356])\n",
            "h: tensor([ 0.2949,  0.2907,  0.5566, -0.6004, -0.4537], grad_fn=<TanhBackward0>)\n",
            "x: tensor([1.5091, 2.0820, 1.7067])\n",
            "h: tensor([-0.0504, -0.8319,  0.6891, -0.0811, -0.9549], grad_fn=<TanhBackward0>)\n",
            "x: tensor([ 2.3804, -1.1256, -0.3170])\n",
            "h: tensor([-0.9035,  0.7153, -0.9110,  0.4101,  0.4610], grad_fn=<TanhBackward0>)\n",
            "x: tensor([-1.0925,  0.8058,  0.3276])\n",
            "h: tensor([ 0.5157,  0.1567,  0.7691, -0.8519, -0.4661], grad_fn=<TanhBackward0>)\n",
            "x: tensor([-0.7607, -1.5991,  0.0185])\n",
            "h: tensor([-0.6471,  0.9578, -0.5932, -0.2097,  0.4347], grad_fn=<TanhBackward0>)\n",
            "x: tensor([-0.7504,  0.1854,  0.6211])\n",
            "h: tensor([ 0.2194,  0.3107,  0.5832, -0.7386, -0.3476], grad_fn=<TanhBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3031,  0.4942, -0.3826, -0.1671, -0.0307],\n",
              "        [ 0.2949,  0.2907,  0.5566, -0.6004, -0.4537],\n",
              "        [-0.0504, -0.8319,  0.6891, -0.0811, -0.9549],\n",
              "        [-0.9035,  0.7153, -0.9110,  0.4101,  0.4610],\n",
              "        [ 0.5157,  0.1567,  0.7691, -0.8519, -0.4661],\n",
              "        [-0.6471,  0.9578, -0.5932, -0.2097,  0.4347],\n",
              "        [ 0.2194,  0.3107,  0.5832, -0.7386, -0.3476]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names_list[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHRzWO_LCd2A",
        "outputId": "e9092ec3-0bd1-4a16-b19e-6ca4913c640c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entire_chars = []\n",
        "\n",
        "for name in names_list:\n",
        "  for char in name:\n",
        "    entire_chars.append(char)\n",
        "\n",
        "len(entire_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_IsnKRz_tP3",
        "outputId": "09f6f633-12f0-4dcd-8486-92251d4990f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196113"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(entire_chars)\n",
        "vocab = list(set(entire_chars))\n",
        "vocab.sort()\n",
        "\n",
        "char2idx = {char: i for i, char in enumerate(vocab)}\n",
        "char2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QglsfOjMDLnY",
        "outputId": "88fd4c7a-5377-4a10-9f56-c64b2e12a603"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 0,\n",
              " 'b': 1,\n",
              " 'c': 2,\n",
              " 'd': 3,\n",
              " 'e': 4,\n",
              " 'f': 5,\n",
              " 'g': 6,\n",
              " 'h': 7,\n",
              " 'i': 8,\n",
              " 'j': 9,\n",
              " 'k': 10,\n",
              " 'l': 11,\n",
              " 'm': 12,\n",
              " 'n': 13,\n",
              " 'o': 14,\n",
              " 'p': 15,\n",
              " 'q': 16,\n",
              " 'r': 17,\n",
              " 's': 18,\n",
              " 't': 19,\n",
              " 'u': 20,\n",
              " 'v': 21,\n",
              " 'w': 22,\n",
              " 'x': 23,\n",
              " 'y': 24,\n",
              " 'z': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Dataset Class"
      ],
      "metadata": {
        "id": "oOJqBIyb9-LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameSet:\n",
        "  def __init__(self, txt_fn):\n",
        "    txt_string = read_txt(txt_fn)\n",
        "    names_list = [x.replace('\\n', '') for x in txt_string]\n",
        "    self.data = names_list\n",
        "\n",
        "    for name in names_list:\n",
        "      for char in name:\n",
        "        entire_chars.append(char)\n",
        "\n",
        "    self.vocab = list(set(entire_chars))\n",
        "    self.vocab.sort()\n",
        "\n",
        "    special_tokens = ['<pad>', '<start>', '<end>']\n",
        "    self.vocab = special_tokens + self.vocab\n",
        "\n",
        "    self.char2idx = {char: i for i, char in enumerate(self.vocab)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    name_string = self.data[idx]\n",
        "    name_in_idx = [self.char2idx[char] for char in name_string]\n",
        "    name_in_idx = [self.char2idx['<start>']] + name_in_idx + [self.char2idx['<end>']]\n",
        "\n",
        "    model_input = name_in_idx[:-1]\n",
        "    target_output = name_in_idx[1:]\n",
        "    return model_input, target_output\n",
        "\n",
        "dataset = NameSet('names.txt')\n",
        "dataset.data[0]\n",
        "len(dataset)\n",
        "dataset.vocab\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkSkKtMU96Ao",
        "outputId": "15f1af3b-6422-4cd1-a2ac-1b18c8b1a617"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 7, 15, 15, 3], [7, 15, 15, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'emma'\n",
        "\n",
        "for char in name:\n",
        "  print(char, char2idx[char])\n",
        "\n",
        "new = [char2idx[char] for char in name]\n",
        "new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8LwkH4L_vyF",
        "outputId": "38b5ff1c-88ca-47e9-b592-6da31e1af8a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e 4\n",
            "m 12\n",
            "m 12\n",
            "a 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 12, 12, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "W8Ow7Weg-XhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim=16):\n",
        "    super().__init__()\n",
        "    self.vocab_size = len(dataset.vocab)\n",
        "    self.emb = nn.Embedding(embedding_dim=embedding_dim, num_embeddings=self.vocab_size)\n",
        "    self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=2*embedding_dim)\n",
        "    self.proj = nn.Linear(in_features=2*embedding_dim, out_features=vocab_size)\n",
        "    # size랑 feature의 수를 계산하는 것이 중요\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x)\n",
        "    x, last_hidden = self.rnn(x)\n",
        "    x = self.proj(x)\n",
        "    x = torch.softmax(x, dim=1)\n",
        "    return x\n",
        "\n",
        "vocab_size = len(dataset.vocab)\n",
        "model = LanguageModel(vocab_size)\n",
        "model.emb.weight\n",
        "\n",
        "x, y = dataset[0]\n",
        "x = torch.tensor(x)\n",
        "print(x)\n",
        "print(model(x).shape)\n",
        "model(x)\n"
      ],
      "metadata": {
        "id": "CqmLowgp-Zjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00314a9b-45f1-441f-a5b1-10ec5df69373"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  7, 15, 15,  3])\n",
            "torch.Size([5, 29])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0293, 0.0325, 0.0432, 0.0398, 0.0362, 0.0378, 0.0388, 0.0281, 0.0341,\n",
              "         0.0417, 0.0292, 0.0403, 0.0281, 0.0287, 0.0395, 0.0391, 0.0340, 0.0381,\n",
              "         0.0306, 0.0251, 0.0355, 0.0304, 0.0362, 0.0397, 0.0314, 0.0353, 0.0299,\n",
              "         0.0282, 0.0394],\n",
              "        [0.0312, 0.0299, 0.0464, 0.0381, 0.0328, 0.0335, 0.0411, 0.0298, 0.0333,\n",
              "         0.0345, 0.0270, 0.0339, 0.0346, 0.0287, 0.0343, 0.0394, 0.0349, 0.0331,\n",
              "         0.0322, 0.0294, 0.0269, 0.0344, 0.0405, 0.0417, 0.0258, 0.0451, 0.0388,\n",
              "         0.0331, 0.0358],\n",
              "        [0.0306, 0.0346, 0.0379, 0.0414, 0.0330, 0.0366, 0.0331, 0.0281, 0.0304,\n",
              "         0.0376, 0.0299, 0.0338, 0.0370, 0.0286, 0.0391, 0.0376, 0.0383, 0.0330,\n",
              "         0.0331, 0.0325, 0.0282, 0.0343, 0.0449, 0.0353, 0.0278, 0.0413, 0.0368,\n",
              "         0.0316, 0.0334],\n",
              "        [0.0300, 0.0375, 0.0348, 0.0416, 0.0320, 0.0386, 0.0299, 0.0271, 0.0294,\n",
              "         0.0389, 0.0314, 0.0346, 0.0383, 0.0283, 0.0409, 0.0381, 0.0401, 0.0329,\n",
              "         0.0327, 0.0340, 0.0285, 0.0339, 0.0467, 0.0323, 0.0285, 0.0395, 0.0360,\n",
              "         0.0315, 0.0323],\n",
              "        [0.0320, 0.0343, 0.0407, 0.0306, 0.0255, 0.0344, 0.0321, 0.0320, 0.0295,\n",
              "         0.0386, 0.0308, 0.0298, 0.0448, 0.0262, 0.0352, 0.0439, 0.0352, 0.0306,\n",
              "         0.0348, 0.0382, 0.0305, 0.0337, 0.0398, 0.0373, 0.0255, 0.0488, 0.0340,\n",
              "         0.0330, 0.0381]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training Loop"
      ],
      "metadata": {
        "id": "ko5F2LlJ-aMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = dataset[0]\n",
        "x = torch.tensor(x)\n",
        "y = torch.tensor(y)\n",
        "prediction = model(x)\n",
        "print(y)\n",
        "prediction\n",
        "\n",
        "prob_of_correct_char = prediction[torch.arange(len(y)), y]\n",
        "prob_of_correct_char\n",
        "nll = -torch.log(prob_of_correct_char)\n",
        "nll.mean()"
      ],
      "metadata": {
        "id": "65wtMbwa-b_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c366f6-7094-463b-8cc6-f1c8f141887f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 7, 15, 15,  3,  2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.2939, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}